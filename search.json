[
  {
    "objectID": "news/2023-i3-open-data-fellows/index.html",
    "href": "news/2023-i3-open-data-fellows/index.html",
    "title": "2023 I3 Open Data Fellows",
    "section": "",
    "text": "The Innovation Information Initiative awarded five fellowships to PhD students focused on innovation research in 2023. Four of these fellows presented their work at the December Technical Working Group meeting."
  },
  {
    "objectID": "news/2023-i3-open-data-fellows/index.html#fellows-and-projects",
    "href": "news/2023-i3-open-data-fellows/index.html#fellows-and-projects",
    "title": "2023 I3 Open Data Fellows",
    "section": "Fellows and Projects",
    "text": "Fellows and Projects\n\nAlexander Kann (University of Mannheim)\nProject: “Patents or Defensive Disclosures?”\nFocus: Building a BERT classifier to match defensive disclosures with patent technology classifications\nAlexander developed a sophisticated classifier using BERT (Bidirectional Encoder Representations from Transformers) to identify and match defensive disclosures with their corresponding patent technology classifications. This work addresses the challenge of distinguishing between formal patents and defensive publications, which are increasingly used by companies to prevent others from patenting specific innovations without going through the full patent process themselves.\n\n\n\nBernardo Dionisi (Duke University)\nProject: “Pydrad”\nFocus: Developed an open-source Python package for constructing and analyzing innovation datasets\nBernardo created Pydrad, an open-source Python package designed to streamline the construction, transformation, combination, and comparison of innovation datasets. This tool addresses a critical need in the innovation research community for standardized methods to work with diverse data sources. The package provides researchers with a useful index and workflow tools that make complex dataset manipulation more accessible and reproducible.\n\n\n\nSaqib Mumtaz (UC Berkeley)\nProject: “Linking Scientific Articles to Media Mentions”\nFocus: Connected EurekaAlert data to OpenAlex author information to examine media impact on scientific discoveries\nSaqib’s research connects scientific publications with their media coverage by linking EurekaAlert press release data to OpenAlex author information. By using CrossRef dates for improved matching accuracy, this work examines how the science promotion landscape influences innovation visibility and the broader impact of scientific discoveries. This dataset enables researchers to study the relationship between media attention and scientific impact in new ways.\n\n\n\nMaya Durvasula (Stanford University)\nProject: “Statistical Evidence from Clinical Trials”\nFocus: Used large language models to combine clinical trial records with publication and FDA approval data\nMaya applied large language models to integrate three critical data sources: clinical trial records from ClinicalTrials.gov, scientific publications, and FDA approval data. This integration creates a comprehensive new clinical trial results dataset that researchers can use to study the relationships between trial design, publication patterns, and regulatory outcomes. The work demonstrates how modern NLP techniques can extract and structure information from diverse biomedical data sources.\n\n\n\nMatteo Tranchero (UC Berkeley)\nProject: “Analysis of Knowledge Entities”\nFocus: Developed a metric for measuring innovation impact through attention directed at knowledge entities rather than citations\nMatteo utilized Bio-BERT to develop a novel innovation impact metric based on “knowledge entities” rather than traditional citation counts. This approach measures how attention shifts toward specific concepts and ideas over time, providing a more nuanced view of scientific impact that captures influence beyond simple citation patterns. By tracking knowledge entities, the metric can identify important innovations that may be widely discussed and built upon without necessarily being heavily cited in the traditional sense.\n\nPublished October 4, 2024. Original content on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)."
  },
  {
    "objectID": "fellows/alumni/laura-shupp/index.html",
    "href": "fellows/alumni/laura-shupp/index.html",
    "title": "Laura Shupp",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  },
  {
    "objectID": "fellows/alumni/saqib-mumtaz/index.html",
    "href": "fellows/alumni/saqib-mumtaz/index.html",
    "title": "Saqib Mumtaz",
    "section": "",
    "text": "i3 Fellow, 2024 Cohort"
  },
  {
    "objectID": "fellows/alumni/matteo-tranchero/index.html",
    "href": "fellows/alumni/matteo-tranchero/index.html",
    "title": "Matteo Tranchero",
    "section": "",
    "text": "i3 Fellow, 2024 Cohort"
  },
  {
    "objectID": "fellows/alumni/mihai-codreanu/index.html",
    "href": "fellows/alumni/mihai-codreanu/index.html",
    "title": "Mihai Codreanu",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  },
  {
    "objectID": "fellows/alumni/kyoungah-noh/index.html",
    "href": "fellows/alumni/kyoungah-noh/index.html",
    "title": "Kyoungah Noh",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  },
  {
    "objectID": "fellows/alumni/maya-durvasula/index.html",
    "href": "fellows/alumni/maya-durvasula/index.html",
    "title": "Maya Durvasula",
    "section": "",
    "text": "i3 Fellow, 2024 Cohort"
  },
  {
    "objectID": "fellows/current/piyasha-majumdar/index.html",
    "href": "fellows/current/piyasha-majumdar/index.html",
    "title": "Piyasha Majumdar",
    "section": "",
    "text": "i3 Fellow, 2026 Cohort"
  },
  {
    "objectID": "fellows/current/yujing-huang/index.html",
    "href": "fellows/current/yujing-huang/index.html",
    "title": "Yujing Huang",
    "section": "",
    "text": "i3 Fellow, 2026 Cohort"
  },
  {
    "objectID": "fellows/current/marco-panuzi/index.html",
    "href": "fellows/current/marco-panuzi/index.html",
    "title": "Marco Panuzi",
    "section": "",
    "text": "i3 Fellow, 2026 Cohort"
  },
  {
    "objectID": "bigquery.html",
    "href": "bigquery.html",
    "title": "i3 BigQuery Data Workspace",
    "section": "",
    "text": "The i3 BigQuery Data Workspace is a collaborative Google BigQuery project hosting curated datasets for innovation and science policy research. Maintained by the Innovation Information Initiative (i3), this workspace provides researchers with cloud-based access to comprehensive patent, publication, and innovation-related data.\nThis guide covers access information, available datasets, query patterns, and best practices for working with the data.\n\n\n\n\n\n\nNoteStay Connected\n\n\n\nJoin our Google Group for announcements, community discussions, and technical support."
  },
  {
    "objectID": "bigquery.html#overview",
    "href": "bigquery.html#overview",
    "title": "i3 BigQuery Data Workspace",
    "section": "",
    "text": "The i3 BigQuery Data Workspace is a collaborative Google BigQuery project hosting curated datasets for innovation and science policy research. Maintained by the Innovation Information Initiative (i3), this workspace provides researchers with cloud-based access to comprehensive patent, publication, and innovation-related data.\nThis guide covers access information, available datasets, query patterns, and best practices for working with the data.\n\n\n\n\n\n\nNoteStay Connected\n\n\n\nJoin our Google Group for announcements, community discussions, and technical support."
  },
  {
    "objectID": "bigquery.html#getting-started",
    "href": "bigquery.html#getting-started",
    "title": "i3 BigQuery Data Workspace",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Prerequisites\nBefore accessing the i3 repository, you will need a Google Cloud account with billing enabled. New users receive complimentary credits that are sufficient for substantial initial analysis.\n\n\n2.2 Accessing the Repository\nStep 1: Navigate to Google Cloud Console and sign in or create an account.\nStep 2: Open BigQuery from the Cloud Console navigation menu.\nStep 3: In the Explorer panel, click Add → Star a project by name and enter: nber-i3\nStep 4: The i3 datasets will appear in your Explorer panel, ready for querying."
  },
  {
    "objectID": "bigquery.html#available-datasets",
    "href": "bigquery.html#available-datasets",
    "title": "i3 BigQuery Data Workspace",
    "section": "3 Available Datasets",
    "text": "3 Available Datasets\nThe repository contains two categories of datasets: raw data sources and derivative datasets contributed by the research community.\n\n3.1 Core Datasets\n\n\n\nDataset\nDescription\nLink\n\n\n\n\nCrossref\nScholarly metadata and DOI registration records (bulk)\nCrossref Public Data File\n\n\nCrunchBase (2013)\nStartup ecosystem and venture capital data\n—\n\n\nOpenAlex\nCatalog of scholarly works, authors, institutions, and citation networks\nopenalex.org\n\n\nOrange Book\nFDA-approved drug products with patent and exclusivity info\nFDA Orange Book Data Files\n\n\nPatentsView\nComplete patent data from the USPTO\nPatentsView Data Downloads\n\n\nRetraction Watch\nDatabase of retracted scientific publications\nRetraction Watch\n\n\nUSPTO Patent Assignment\nPatent ownership transfers and assignment records\nUSPTO Patent Assignment Dataset\n\n\n\n\n\n3.2 Community-Developed Datasets\n\n\n\nDataset\nDescription\nCitation\n\n\n\n\nBritish Historic Patents\nHistorical UK patent records\nBerkes, Chen & Tranchero (2026)\n\n\nCommercial Potential of Science\nMeasures of commercial potential of science\nMasclans, Hasan & Cohen (2025)\n\n\nDISCERN\nPatenting and scientific publications by U.S. publicly listed firms\nArora, Belenzon, Cioaca, Sheer, Shin & Shvadron (2024)\n\n\nFounding Patents\nAssignee age at patent grant\n—\n\n\nGeocoding of Worldwide Patent Data\nGeographic coordinates for inventors and assignees\nde Rassenfosse, Kozak & Seliger (2019)\n\n\nHistPat\nHistorical patents with harmonized geography\nPetralia, Balland & Rigby (2016)\n\n\nInventor Age\nInventor demographic and career-stage information\n—\n\n\nJCIF\nJournal Commercial Impact Factor\nMarx & Fuegi (2019); Bikard & Marx (2020)\n\n\nKPSS Patent Value\nStock market-based patent valuations\nKogan, Papanikolaou, Seru & Stoffman (2017)\n\n\nPaper Twins\nMatched paper pairs\nBikard & Marx (2020)\n\n\nPatent Hubs\nGeographic clustering of innovation\n—\n\n\nPatent Paper Pairs\nLinked patent-publication data\n—\n\n\nPatent Scope\nPatent breadth and technological coverage measures\n—\n\n\nPQRS\nPatent quality and relevance scores\n—\n\n\nReliance on Science\nPatent citations to scientific literature\nMarx & Fuegi (2020, 2022)"
  },
  {
    "objectID": "bigquery.html#querying-the-data",
    "href": "bigquery.html#querying-the-data",
    "title": "i3 BigQuery Data Workspace",
    "section": "4 Querying the Data",
    "text": "4 Querying the Data\n\n4.1 BigQuery Console\nThe BigQuery web interface provides an integrated development environment with syntax highlighting, autocomplete, query history, and real-time cost estimation. For most users, this is the recommended starting point.\n\n\n4.2 SQL Query Example\nThe following query retrieves all citations to patents held by a specific assignee:\nSELECT \n    citing_patent_id,\n    cited_patent_id,\n    citation_date\nFROM \n    `nber-i3.patentsview.citations`\nWHERE \n    cited_assignee = 'Xerox'\nThis query typically scans approximately 10 GB of data, costs around $0.015, and completes in 15–20 seconds.\n\n\n4.3 Python Integration\nfrom google.cloud import bigquery\n\n# Initialize client with your project\nclient = bigquery.Client(project=\"your-project-id\")\n\nquery = \"\"\"\n    SELECT *\n    FROM `nber-i3.openalex.works`\n    WHERE publication_year = 2023\n    LIMIT 1000\n\"\"\"\n\ndf = client.query(query).to_dataframe()\n\n\n\n\n\n\nTipAuthentication\n\n\n\nEnsure you have configured Google Cloud credentials. Run gcloud auth application-default login or set the GOOGLE_APPLICATION_CREDENTIALS environment variable.\n\n\n\n\n4.4 R Integration\nlibrary(bigrquery)\n\nproject_id &lt;- \"your-project-id\"\n\nsql &lt;- \"\n    SELECT *\n    FROM `nber-i3.openalex.works`\n    WHERE publication_year = 2023\n    LIMIT 1000\n\"\n\nresults &lt;- bq_project_query(project_id, sql)\ndf &lt;- bq_table_download(results)\n\n\n4.5 Jupyter Notebooks\nBigQuery provides integrated notebook support directly in the Cloud Console, enabling combined SQL and Python workflows without additional setup."
  },
  {
    "objectID": "bigquery.html#dataset-documentation",
    "href": "bigquery.html#dataset-documentation",
    "title": "i3 BigQuery Data Workspace",
    "section": "5 Dataset Documentation",
    "text": "5 Dataset Documentation\nEach dataset includes comprehensive documentation covering variable definitions, temporal coverage, licensing terms, and required citations. Review this documentation before beginning your analysis.\n\n\n\n\n\n\nWarningCitation Requirements\n\n\n\nWhen publishing research using i3 data, you must cite the original data sources as specified in each dataset’s documentation. Failure to provide proper attribution may violate data use agreements."
  },
  {
    "objectID": "bigquery.html#cost-management",
    "href": "bigquery.html#cost-management",
    "title": "i3 BigQuery Data Workspace",
    "section": "6 Cost Management",
    "text": "6 Cost Management\n\n6.1 Pricing Model\nBigQuery uses a consumption-based pricing model. Charges are based on the volume of data scanned, not the size of results returned. The current rate is approximately $6.25 per terabyte of data processed.\nStorage costs for i3 datasets are covered by the initiative—users pay only for query execution.\n\n\n6.2 Cost Optimization Strategies\nSelect specific columns. Avoid SELECT * queries. BigQuery is columnar, so selecting fewer columns reduces scanned data proportionally.\nFilter on partitioned columns. Many tables are partitioned by date or year. Filtering on these columns significantly reduces costs.\nUse the query validator. Before execution, the console displays estimated bytes scanned and cost.\nLeverage caching. Identical queries within 24 hours return cached results at no additional cost.\nApply TABLESAMPLE during exploration. When investigating data structure, use TABLESAMPLE SYSTEM (10 PERCENT) clauses to minimize costs."
  },
  {
    "objectID": "bigquery.html#contributing-to-the-repository",
    "href": "bigquery.html#contributing-to-the-repository",
    "title": "i3 BigQuery Data Workspace",
    "section": "7 Contributing to the Repository",
    "text": "7 Contributing to the Repository\nThe i3 repository welcomes contributions from the research community. Researchers may contribute derived datasets, share analysis workflows, or participate in data curation efforts.\n\n7.1 Contributing a Dataset\nTo contribute a dataset to the i3 repository, follow these steps:\nStep 1: Upload your dataset to an independent Google Cloud project (your own project or a project you control).\nStep 2: Make the dataset publicly accessible by sharing it with allUsers and granting them the BigQuery Data Viewer role:\n\nIn the BigQuery console, navigate to your dataset\nClick on the dataset name, then select Sharing → Permissions\nClick Add Principal\nIn the “New principals” field, enter: allUsers\nSelect the role: BigQuery Data Viewer\nClick Save\n\nStep 3: Contact the i3 team with:\n\nA description of your dataset\nThe project ID and dataset name where your dataset is hosted\nIts research applications\nAny associated publications and citation instructions\n\nStep 4: The i3 team will review your dataset. If accepted, we will clone into the i3 repository, making it available to the broader research community."
  },
  {
    "objectID": "bigquery.html#support-and-resources",
    "href": "bigquery.html#support-and-resources",
    "title": "i3 BigQuery Data Workspace",
    "section": "8 Support and Resources",
    "text": "8 Support and Resources\n\n8.1 Community Discussion\nFor questions, announcements, and collaboration opportunities, join the i3 BigQuery Google Group: https://groups.google.com/g/i3-bigquery\n\n\n8.2 External Documentation\n\nGoogle BigQuery Documentation\nBigQuery SQL Reference"
  },
  {
    "objectID": "events/2022-technical-working-group/index.html",
    "href": "events/2022-technical-working-group/index.html",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "",
    "text": "December 2-3, 2022 | Cambridge, MA (NBER) | Agenda"
  },
  {
    "objectID": "events/2022-technical-working-group/index.html#building-a-corpus-of-patent-article-siblings",
    "href": "events/2022-technical-working-group/index.html#building-a-corpus-of-patent-article-siblings",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "Building a Corpus of “Patent-Article Siblings”",
    "text": "Building a Corpus of “Patent-Article Siblings”\nJean-Marc Deltorn, University of Strasbourg Dominique Guellec, Observatoire des Sciences et Techniques\nJiangyin Liu, Observatoire des Sciences et Techniques\nChenyin Wu, University of Strasbourg\nScientific papers can serve as a background approximation to the field in which the patent exists. Trying to use citations for this has limitations. So does language similarity: Language serves different purposes in the scientific and patent worlds. Standards of clarity are different.\nKeywords are brittle: latent semantic analysis is not currently capable of going beyond the style to the underlying technical object. We are looking at embeddings, and want to evaluate whether text embeddings can discriminate true patent-paper pairs from non-pairs.\nWe started with a manual ground-truth corpus. Chose a subset of domains and their CPC codes. Then evaluated different embeddings: GANs, transformers, and other models, and developed a classifier based on them.\nSelection of corresponding articles: based on inventor last names, pub date, and priority date. Then querying the resulting corpus, looking at Jaccard index, date difference, and text embedding difference (of abstracts)…\nOngoing work: - Extend to other technical fields (ML, crypto, quantum computing, ARNm) - Build a public corpus of field-dependent PPPs\nFuture work: - Extend to other sources (preprints, other media) - Fine tune language models - Address limitations: reliance on author/inventor names\nDiscussion:\nQ: Timeframe?\nA: We want to extend this to a much larger set…\nQ: How do you ensure patent/paper have an overlapping author?\nA: We query Semantic Scholar, to maximize proximity of patent + author.\nQ: My understanding is that there are differences normatively and legally re: what counts in being an author / inventor. How do you think about that?\nA: The rules are different, though it’s a similar principle in Europe and the US.\nComment: Great to see this, fantastic use of patent data. As you expand on this project: institutional affiliation could help evaluate some matches. And have you considered looking at full claims, not just abstracts? A: Yes, affiliation is interesting. A: Our experience from a first test was that the full claim tree did not add much value in classifying true matches, and takes a lot of computation time. (LeeF: seconded)\nComment: Affiliations are missing for 20% of OpenAlex. When there are multiple authors + institutions, they don’t always link correctly.\nComment: From the other side, patents from universities can be assigned to someone else (a grant provider, a startup) leading to other notable gaps.\nComment: This is a perfect example of what we want presented at this workshop: a sense of what’s going on, before it is finalized. Thank you!\nQ: (Adam) In your first slide you had something about “we looked at PPP to understand the relation b/t science and invention. If we knew which were the pairs: can we use this analysis to get a deeper understanding b/t the science and the invention? And predict which science linked to which inventions would produce valuable inventions?\nA: That’s part of the idea, one of my colleagues (Dominique?) should join there. That’s a longer goal, to get that kind of understanding. A: Often you might take inspiration from a scientific idea…\nNB: Lee Fleming is talking about related work tomorrow."
  },
  {
    "objectID": "events/2022-technical-working-group/index.html#patents-phrase-to-phrase-semantic-matching-dataset",
    "href": "events/2022-technical-working-group/index.html#patents-phrase-to-phrase-semantic-matching-dataset",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "Patents Phrase to Phrase Semantic Matching Dataset",
    "text": "Patents Phrase to Phrase Semantic Matching Dataset\nGrigor Aslanyan, Google\nIan Wetherbee, Google\nThis is a new public phrase-to-phrase dataset for semantic textual similarity (STS): the Google Patent Phrase Similarity Dataset\n\nHuman rated, contextual, focused on technical terms, w/ similarity scores\nWith granular ratings/flags (e.g. synonym, antonym, hypernym, hyponym, holonym, shared domain, unrelated…)\n\nExisting STS collections build on Wikipedia, books, &c. not technical terms.\nOur dataset was used in a Kaggle competition in March 2022.\nWe focused on phrase disambiguation (adding CPCs for context), adversarial keyword matching, and hard negatives (explicit non-relation).\nMethod:\nChoosing anchors: - We keep phrases that appear in 100+ patents - Randomly choosing 1000 anchor phrases from these - Randomly sampling up to 4 CPC classes for each, for context\nGenerating targets: - We randomly select phrases from the full corpus with a partial keyword match with an anchor - We use a masked language model, asking BERT to generate replacement phrases after masking out each instance of the phrase\nDiscussion:\nThis is meant to be a tool to fine tune models rather than intended as a model itself.\n\n6:30 pm — Dinner"
  },
  {
    "objectID": "events/2022-technical-working-group/index.html#mapping-patents-to-technology-standards-slides",
    "href": "events/2022-technical-working-group/index.html#mapping-patents-to-technology-standards-slides",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "Mapping Patents to Technology Standards (slides)",
    "text": "Mapping Patents to Technology Standards (slides)\nFabian Gaessler, Pompeu Fabra University\nDietmar Harhoff, Max Planck Institute for Innovation and Competition\nLorenz Brachtendorf, Max Planck Institute for Innovation and Competition\nSummary: We try a new method to link patents to standards based on semantic similarity. Useful for SEP litigation, strategic patenting, contributions to tech progress.\nFuture Improvements: Refine similarity measure, extend to other standards, historical and other regions.\nData sources + challenges: - Standards: We focus on ETSI - a standards db with 40k standard docs, varying in size &gt;1k pages, may describe multiple technologies and split at a chapter level - Also 18,000 declared SEPs, at family level - Challenges: long texts, multiple docs, two corpora\nSimilarity approaches: - octimine: closed-source, via Natterer(2016). ‘vector space model’, cosine + other? fine tuning - tf-idf, embeddings: we checked results with this\nLinking essentiality status to predicted essentiality: “if this worked better I would be out founding a company offering patent-tech”\nWe compared this w/ wifi patents, and hand-marked gold standard, w/ similar results.\n\nWe posted everything on Harvard Dataverse: with csv’s for 60k docs, use cases, and more. Semantic similarity of patent-standard pairs (ETSI, IEEE, ITUT)\nDiscussion:\nTim: We are basically citing one another’s unpublished papers here. Great to see this. Can you say more about similarity score coeffs and how this changes for claims? A: With claims: Effect size gets smaller. There’s a tradeoff b/t the noise you have from just having [claims] vs [standards], and bias that may come in (from also looking at description, less uniform?). A: Also interesting that the final decisions (across the corpus) didn’t change that much when using just claims or using full.\nTim: Ideas - take claim + description, find ones that are more similar on one or the other. Perhaps claims change in ways that make them fall w.r.t. standard. There’s such time variation in patenting and standardization processes, this micro-longitudinal change could show which ones move in or away from specs. From a policy standpoint: can you find things that were close substitutes but isn’t essential? Policy debate here is that stands process created a monopoly that wasn’t there before. So: what were the alternatives early in stands? A: We looked at undeclared-by-humans but high-similarity. Overall seem less valuable. Also much older at the time; patent had expired. Share of SSO membership was not lower among these.\nComment: One way to get essentiality is to put language in your patent into the standard (in one direction or the other). Given the slow standards process, you have opportunities through continuations + more. My concern w/ this approach: it’s not that patents are written in a eureka moment, and language summarizes that insight! A: This is complex. There are some just-in-time patenting studies, also personal ties: can you see prelim drafts, file a patent just before adoption? This is an issue for many such efforts.\nAdam: Sounds like you could document this phenomenon by looking at increasing similarity over the course of the standards process."
  },
  {
    "objectID": "events/2022-technical-working-group/index.html#the-nber-orange-book-dataset-a-users-guide",
    "href": "events/2022-technical-working-group/index.html#the-nber-orange-book-dataset-a-users-guide",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "The NBER Orange Book Dataset: A User’s Guide",
    "text": "The NBER Orange Book Dataset: A User’s Guide\nMaya Durvasula, Stanford University\nScott Hemphill, NYU Law School\nLisa Larrimore Ouellette, Stanford University\nBhaven Sampat, Columbia University and NBER\nHeidi Williams, Stanford University and NBER\nPatents are used as measure of innovation; but mappings to products can be unclear. There’s no straightforward linkage. But this is different in pharma, via the Orange Book.\nWe introduce a newly digitized OA dataset of Orange Book records, w/ annual editions providing snapshots at points in time; giving a comprehensive portrait of legal protections over drug lifecycles.\nChallenges: - OB records are self-reported, not audited by the FDA. We validated against external benchmarks - Appropriate use may differ across researchers. Use case: calculating market exclusivity\n“Orange Book” is a misnomer. Real name: Approved Drug Products with Therapeutic Equivalence Evaluations, for pharmacists to track generic-brandname links. Related: Hatch-Waxman Act for drug price competition.\nNot everything is eligible for listing. Only patents that could reasonably be asserted (to track infringement of generics). Incentives to list all patents: generic competitors have to challenge every patent that’s still in force at the point they enter the market. [challenge means: legal certification, required to argue each specific patent is either invalid or not infringed]\nAny infringement suit leads to 30 months of blocking generic approval. Free extra exclusivity! Sometimes called ‘pseudo-patents’. We see 5 categories of exclusivity:\n\nNew chemical entity (NCE): 5y\nOrphan drug (ODE): 7y\nPediatric (PED): 6mo\nGenerating Antibiotic Incentives Now (GAIN): 5y\n180-day exclusivity (Generic DE): 6mo\n\nFind our dataset on NBER: the NBER Orange Book Dataset (Readme).\nGood news: you can just use this w/o worrying about gaps! [4 data files: Drug patents, patent use codes, drug exclusivity, drug exclusivity code…]\nOf 2500 new drugs 1985-2015, 80% have one form of such protection. Of 800 new molecular entities, 96% of these ‘innovative drugs’ have one. This exclusivity is granted and recorded directly by FDA.\nWe run a comparison to IQVIA/Ark, look at litigation records, and at extended patents under Hatch-Waxman. The majority of drug patents do get recorded in the Book.\nWe also looked at 4 predictable changes to expiry: 1. TRIPS 2. PT Extension 3. PT Adjustment 4. Maintenance fee non-payment (at 3.5/7.5/11.5)\nAt high level all things are accurate, but non-payment doesn’t appear! Firms just stop self-reporting. 45% of patents expire before full term. Must find other resources to track.\nContext: This was originally an appendix for another project estimating market exclusivity: Nominal, Expected, Realized (what do legal protections say they confer, what shielding should be expected, how much time actually elapsed in a case).\nDiscussion:\nQ: Dan Gross: Could you list some potential misuses as well as good uses of this dataset?\nA: Bhaven: Positive use cases included… Don’t count all entries as if they are equal. E.g. those that actually matter for generic entry.\nErrors/disputes:\nIf you’re a competitor you can state that a record doesn’t actually conflict w/ listed drugs. There are 54 active disputes here, from generic competitors. This is hard if you’re not yourself in the weeds re: what the patent text allows. Our period ends in 2015, and there weren’t disputes that ended in delisting in that period.\nUntil 2003, you could get multiple 30mo stays. Firms would start pulling new OB listings out of nowhere. Had to be fixed in the Medicare Modernization Act.\nQ: Have you thought about how different IP rights complement one another?\nA: The project this was originally an appendix for is doing that: looking at new uses for approved drugs, and how patent + regulatory exclusivity interact. Definitely something you can do with this data!\nComment: [from USPTO] The patent examination research dataset (PatEx) includes patent status, expiry due to non-maintenance. Published annually since 2014. Google Patents may have more, if you need older years reach out and we can track down where it actually is.\nComment: Renewals can be found in PatStat."
  },
  {
    "objectID": "events/2022-technical-working-group/index.html#progress-report-on-an-inventor-author-crosswalk",
    "href": "events/2022-technical-working-group/index.html#progress-report-on-an-inventor-author-crosswalk",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "Progress Report on an Inventor-Author Crosswalk",
    "text": "Progress Report on an Inventor-Author Crosswalk\nLee Fleming, University of California, Berkeley\nWe have initial results, model, and proposed flow.\nThe Gatekeepers of Science: Papers for pure sci, Light bulb for pure inventor, Gate for sciinventor.\nRelationship width: # of coauthorships. Heterogeneity across lab clusters?\nArtefacts: - Sankey diagram of Doudna’s OA ID / PatsView ID shows over-splitting in OA - For a ML model estimating missed links: - Take subset of Marx/Fuegi patent-article citations that are self-citations. Look for scientists w/ ORCID IDs [‘best thing we have right now’] - Features of prediction model: many! Clean up all fields, plug in, publish accuracy estimates - Enable sub-setting, intermediate results\n\nSome features used in distance calculation.\nChallenges: Queries directly draw from OAlex right now. Encoding takes time. For clustering, let users choose an algorithm, show both sanity check + confidence measure.\nDiscussion:\nLee: Our server died, so we’re trying to figure out the economies of hosting own servers and BigQuery.\nQ: Say more about this? How could BQ help?\nA: Some IT guys suggested using [it] to help keeping this running. NB: For Gaetan, curation feels like the critical upkeep cost.\nQ: What are the most expensive parts of keeping this updated?\nA: OA updates their dataset every 6mo. PatentsView each year. We want to turn the crank. Needs ~10k compute each time…\nOA is changing in real time, since last year. Maybe they’re trying to cluster researchers. (A: we should incorporate those)\nQ: Are you using OA’s field concepts? They’re a bit wonky, too sparse, too many of them associated w/ each researcher.\nA: We’re using those and rolling our own, trying both. I’m a pathological case: my patents are in materials science, and I’m a social scientist now. A: (Adam) I waded into this in NZ, looking at the work of NZ scientists who worked in NA/Europe and returned. Typically in db’s they are treated as different people. Different location + institution! May be impossible to handle. A: Doesn’t seem impossible for a human, or a great machine reader (esp if they can trace the full timeline of other work of each person).\nQ: Is there a way to [use email to prompt to dig deeper]?\nQ: What fraction of scientists have an ORCID?\nA: As of 2022: about 6M distinct ORCIDs are associated with at least one work or external identifier. Recency bias."
  },
  {
    "objectID": "events/2022-technical-working-group/index.html#panel-how-do-we-validate-patent-metrics-derived-from-semantic-analysis",
    "href": "events/2022-technical-working-group/index.html#panel-how-do-we-validate-patent-metrics-derived-from-semantic-analysis",
    "title": "Winter 2022 Technical Working Group Meeting",
    "section": "Panel: How do we validate patent metrics derived from semantic analysis?",
    "text": "Panel: How do we validate patent metrics derived from semantic analysis?\nThere has been an explosion of development of semantic-based measures seeking to capture similarity across patents; novelty; disruptiveness, value or impact, etc. The panel will bring together researchers who’ve been working on these metrics to discuss questions such as: what is the relationship of these metrics to older ones based on, e.g., patent classification or citations; how should validation be structured (should people validate their own measures or should we try to create some kind of shared or over-arching validation process); what is the relationship between different modes of validation (e.g. correlation with existing metrics, testing against subjective expert judgements, correlation with outcome indicators such as productivity or prizes).\nModerator: Bronwyn Hall, Stanford University and NBER Panelists: Sam Arts (KU Leuven), Dokyun Lee (Boston University), Ina Ganguli (UMass Amherst), Josh Lerner (Harvard + NBER)\nApproaches to validation:\n\nInternal validity: expert ratings (13 from 5 fields)\nExternal validity: citations, shared family, shared ID\n\nIdeas: Use new combinations of classes to estimate novelty. Special case: Look at 400 patents that got rare awards. Control case: Not novel / impactful? (US grant, EPO/JPO rejection)\nGeneral remarks: - Preprocessing text makes a big difference - Articulate tradeoffs b/t simple and advanced approaches - Explain why text works better (than trad measures) - Define the goal (better to estimate what?) - We need new benchmarks to validate metrics - To everyone: provide raw data, and the code that processes it! That lets others replicate, vary steps, chain processes\n\nInnoVAE - Generative AI for patent innovation\nWe looked at different representations for innovation.\nToken-based methods, embedding methods, topic methods are used for similarity, but there is no regularization of the learned manifolds/latent spaces, so distances are hard to interpret.\nSemantic orthogonality + dimension independence is not internalized or sharpened → problem of unique interpretability.\nInnovae: Develops Innovation Space — constructing economically interpretable measures, in a well-disentangled representation.\n\nWhat could you get by combining two patents? E.g., combinational creativity for claims. How exceptional is one patent in the context of a portfolio / with respect to one tech factor?\nDesirable features: Multimodal…\n\nInnovation factors for one topical specialty:\n\nOur ideal: A common dataset, task, metric + benchmarks - Compare how speech + language models evolved; Kaggle today - Unite scattered approaches to this for patent/scholarly data\nDownstream application: Predict Tobin’s q.\nDiscussion:\nComment: Cautious optimism about advancing the s.quo with language models.\nQ: Is there a way to look inside black boxes to describe what’s driving the process (and compare options)?\nComment: Limits of language similarity: (Andy Toole) Applicants have an incentive to morph language to differentiate their applications and help overcome objections related to novelty and nonobviousness. Now Bronwyn is talking about strategic language.\n(Adam) One concrete thing that seems to be coming out of this: We should create a parallel index of validation datasets Get everyone [running contests] to compare a) their prize matching[?], b) standard tests to run new measures against. Then referees could say “you have to run your new metric against those testing datasets”.\nJosh’s comments hinted at this: Patents are issued through a resource-intensive admin process. There’s just a lot of eyes on these docs. As we saw today there’s a lot of emphasis on similarity, but we haven’t targeted what Julian was talking about: examination process, assignment to examiners, to a unit, what kinds of rejection specific claims get. - That’s more informed than a lot of RAs who look at patents - That plugs into a community of commercial/professional services [tools to get your patent assigned to a favorable art unit] - If we do things relevant to that community they could come help?\nComment: Validation tasks seem specific to an application… but for human coding, we could draw standards from how to design the coding task. People are expensive, if consistent over time… and a recent emerging patent pool is “Open RAN” for 5g. They decided there was so much IP clamoring to get in, they had to turn it over to computers to determine essentiality. - [Machine reading / synthesis is good enough to get lots of leverage here] - (Adam) We could explore this more systematically - The first AI winter came about due to a lack of shared validation? - Compare how Papers With Code/Papers With Data work now\nMore clarity would be useful for specific common ideas: - Similarity (much more than just cosine of feature vectors) — ex: consider what we’re looking at similarity between - Quality (Bronwyn has a whole chapter on this) - Novelty (compare to what, on what timescale)\nQ: General Q: Is public pair data available?\nA: It is discontinued; queries go through Patent Center\n\n1:00 pm — Lunch\n\nThanks for joining! For further questions or conversation, please join the I3 discussion list (i3-open).\n\nOriginal content published on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)"
  },
  {
    "objectID": "events/2024-technical-working-group/index.html",
    "href": "events/2024-technical-working-group/index.html",
    "title": "2024 Technical Working Group meeting",
    "section": "",
    "text": "December 6-7, 2024"
  },
  {
    "objectID": "events/2024-technical-working-group/index.html#new-ventures-products-and-tools",
    "href": "events/2024-technical-working-group/index.html#new-ventures-products-and-tools",
    "title": "2024 Technical Working Group meeting",
    "section": "4:15 New Ventures, Products, and Tools",
    "text": "4:15 New Ventures, Products, and Tools\n\nDatabase, Methodological Tools, and Research Opportunities: Creative Destruction Lab and Early-Stage Technology Ventures\n\nAmir Sariri (Purdue University), Avi Goldfarb (University of Toronto, NBER)\nCreative Destruction lab: our relational db has 200 linked datasets. Such as a table for meeting notes, w/ granularly linked statements from participants, giving us comment-level data\nCDL data dictionary\nExamples:\n\nThis work in information friction was an RCT.\nDiscussion:\nQ: How are mentors recruited for your mentorship system?\nA: Initially, this was via networks of the program founders.\nQ: I love seeing this data; our first entrepreneurship dataset ever! (well, there’s a 2013 dataset from crunchbase, but that’s it) Tell me more about [the long tail?]\nA: We have application data (for things other than the final vetted applications), it is not as good. We don’t follow up with them b/c they’re not in the program. Be cautious in interpreting that data.\n\n\n\nNew Products\n\nAbhiroop Mukherjee (HKUST), Bruno Pellegrino (Columbia University), Alminas Zaldokas (NUS), Yiman Ren (University of Michigan), Tomas Thornquist (Shell Street Labs)\nWhen a successful new product comes out, we want to look at the change in consumer surplus and the effect on other firms, to see the overall welfare impact. But GDP growth misses this, mainly capturing the increase in existing varieties.\nOur approach is threefold: - build a database of new product introductions, - estimate the profits from these introductions captured by firms, and - estimate spillovers and consumer surplus\nDiscussion:\nQ: Do you study robustness of results around the window you choose around the product announcement? (the market takes time)\nA: Yes, thankfully we have the announcement date which is unambiguous. We see clear discontinuities. With a longer window, the effect gets bigger. (market also anticipates)\nQ: Why not run event studies with competitors?\nA: If you run events firm by firm, you’ll get N^2 studies per year, 25M from 5k competitors. This way we can compute spillovers in closed form w/o looking at those imprecise crossover events.\nQ: What about unpriced spillovers? I would have guessed we’re also interested in knowledge spillovers, which may happen in other years vs contemporaneous. Are you looking only at price information?\nA: Knowledge spillovers may be there, we’re not looking at those. This may be more relevant for patents than new products. Our model by construction can’t capture that.\nQ: About interpretation: what’s the difference between the change in firm profits vs the change across their market happening to all firms in the market?\nA: Yes, we are all playing an oligopoly game, everyone adjusts their output and prices. Equilibrium pricing effects should already be taken into account.\nQ: If you’re only looking at ‘winners’, are the results here inflated?\nA: We’re careful about who we call winners. If a product was not expected to be successful by the market, the normal return would be close to zero. We don’t use the average across all firms; each product-introduction has its own abnormal return.\nQ: In the patent paper, the average return is essentially zero. They do a trip to convert negative returns into positive numbers, so the return to a patent is bounded at zero. You have larger average returns but presumably got negatives — what do you do with them? Are they still negative, or do you transform them so the value is bounded at 0?\nA: In the paper, there’s a signal connected to the patent, which could be positive or negative. They make a distributional assumption, and have a bayesian technique to recover expected signal from the return. We do the same thing, but have a better signal-to-noise ratio, b/c we have a sharp announcement date.\n\n\n\nNovelpy: A Python Package to Measure Novelty and Disruptiveness\n\nPierre Pelletier, Kevin Wirtz (University of Strasbourg)\nWe want to quantify novelty and disruptiveness in science. This underpins peer recogntion and has played a crucial role in science and tech policy. We propose Novelpy, an open source tool that estimates both of these, and displays it graphically, to advance the science of science.\n\nFor disruptiveness, we look at the citation network, and 6 different indicators of disruptiveness. Each one has its critics, so we offer the set of all indicators and let the users decide what to do with the results.\nIn related work, we have previously estimated cognitive diversity and its impact on novelty and impact, looking at PubMed publiations. (Sails and Anchors, 2023)\nDiscussion:\nQ: You’ve run this on PubMed, using abstracts and mesh terms. I work with OpenAlex; it sounds like I could do a preprocessing step to take whatever dataset I want to use, and run your code on it. Is that the way to think about it?\nA: Yes, exactly.\nQ: Say you run across edge cases in your citation network, like 50 references to the same source, or excess self-cites, or a quirk in the source that messed up the citations. Do you have any features that note these issues? A way to flag that someone should doublecheck?\nA: We only check that you have at least 3 references to be included. Each source of papers might have different quirks (in the dataset), we haven’t tried to address this."
  },
  {
    "objectID": "events/2024-technical-working-group/index.html#i3-updates-and-announcements",
    "href": "events/2024-technical-working-group/index.html#i3-updates-and-announcements",
    "title": "2024 Technical Working Group meeting",
    "section": "5:45 I3 updates and announcements",
    "text": "5:45 I3 updates and announcements\n\nIntroducing the I3 BigQuery Data Repository\nDror Shvadron (University of Toronto), on zoom\nThis is a work in progress that we’ve been thinking about for a while. Dror, take it away!\nSomething challenging in our field is we work with large datasets, hard to work with in their original raw form. OpenAlex is 1.5TB. Downloading, grasping its structure, manipulating it, cleaning up discrepancies, merging it with other: all of that takes time, and tacit knowledge to do efficiently.\nNot everyone has the ability to do this, so it’s a barrier to making progress and sharing it with people around the world. This project is trying to extend I3 from identifying the datasets to making it easy to work with, using BigQuery. Allowing data processing (in the cloud) at scale, in a reproducible way.\n\n\nLog into BigQuery from Google Cloud, select +Add a project in the Explorer menu, choose Star a project by name, and use the project name nber-i3.\nThen you’ll be able to browse and query the nber-i3 datasets.\nThere will also be a google group for i3-bigquery (not yet publicly visible)\n\n\n\nIntroducing the 2025 I3 Fellows!\nBhaven Sampat\nThis is the second year of supporting I3 fellows, after an excellent showing last year and interest in expanding the program. We want to welcome our 7 new fellows, all working on open datasets: Laura Shupp, Rebekah Dix, Mihai Codreanu, Tianshu Lyu, Guilherme Junqueira, Kyoungah Noh, and Matthew Lee Chen. Six of them were able to make it to attend the workshop in person! Please say hello and ask them about their work if you see them.\n\n6:15 pm — Dinner reception"
  },
  {
    "objectID": "events/2024-technical-working-group/index.html#building-datasets-with-llms",
    "href": "events/2024-technical-working-group/index.html#building-datasets-with-llms",
    "title": "2024 Technical Working Group meeting",
    "section": "9:00 Building Datasets with LLMs",
    "text": "9:00 Building Datasets with LLMs\n\nLLM-based Topic Modeling\n\nVictor Lyonnet (University of Michigan), Amin Shams, Shaojun Zhang (The Ohio State University)\nWe analyzed 6,800 expert consultation calls from 1,700+ companies, and tried to quantify topic-specific sentiment and extract signals predictive of the resulting deal outcome.\nWe used LLMs to help with these steps. (GPT4 via UMich Azure account). LMs can help because the transcripts are complex, with intricate structure, and topic-level sentiment rather than document-level sentiment; hard for traditional LDAs. There are important caveats here: prompt word choice can easily bias the results.\nTopic modeling: we generate them from a 20% sample, cluster and standardize them, then assign them to all transcripts. We see that topics vary a lot by sector, for instance drinks and beverages focus a lot on the competitive market.\n\nWe find that many topics have low predictive power, but a few (positive discussion of technology, positive customer signal) are strongly predictive.\nDiscussion:\nQ: Working with ChatGPT style LLMs I’ve found problems increase with larger texts. If you are working with 3 hour transcripts, how do you deal with this?\nA: Depends on how specifically you define a prompt. The more you want to find fine-grained features of individual paragraphs or pages, the more we found this is an issue.\n\n\n\nA Robust Green Patent Database\n\nYuan Sun (Shanghai University of Finance and Economics), Xuan Tian, Yuanchen Yang (Tsinghua University)\nAn easy way to find green patents is through CPC and EPO labels for sustainable tech. We looked at 580K patents with labels that were associated with green patents. This included CPC classes that are potentially underrepresented in existing catalogs of green patents, expanding on the EPO’s Y02 classification. We used GPT 4o-mini to initially assess patents for whether they were ‘green’. 19% of Y02 patents were assessed at low confidence for being green, while an additional 13% of identified green patents were not in Y02.\nThen we compiled a training dataset from these initial assessments, with twice as many negative as positive examples. Finally, we produced detailed descriptions of each patent using GPT 4o-latest.\nIssues we faced: we validated each step across different models to find the most efficient one that did what we needed, to keep costs down. Wanted all steps to fit into a mobile device, limiting the need to check a website.\nCode is open: see yuanresearch/Robust-Green-Patents-Paper You need to use your own API token\nDiscussion:\nQ: Did you compare this approach across green frameworks?\nA: I think that’s the next step. We did only 100 samples here. This db should include all green innovations worldwide; we started with transportation patents. The framework has the potential to expand.\nQ: How robust do you expect this classification to be over time?\nA: It should get better over time as we refine the model. Q: (But was the question about whether a single model would be persistently good across years, compare to how CPC codes are applied?)\nQ: How sensitive was this work on the choice of CPC codes at the start?\nQ: Some patents are for a technology that is ambiguously related to environmental sustainability. Is a traffic-efficiency tool that increases the demand for driving good or bad for the environment? Are LLMs good or bad at this nuance?\n\n\n\nDistilling Data from Large Language Models\n\nMaya Durvasula, Sabri Eyuboglu, David Micha. Ritzwoller (Stanford University)\nWe want to collect and organize public information about the design and outcomes of pharma clinical trials.\nWorking with clinicaltrials.gov and PubMed was not always straightforward. About 3000 sponsors haven’t fully published trial results, some proprietary databases take public db’s as an input, and it’s hard to tell whether the changes in them result from updated reporting, or their interpretation and cleaning.\nTechnical results: we can get comparable effects to using the most advanced ChatGPT, by using LLMs with the transparency and reproducibility of open source models, at 3% of the cost. Our model was superior than 7 traditional regressions, on measure of both true and false positive rates (but especially the latter).\nAsides: There are 7 tags for clinical trials. Many other studies only use one of the 7. There are many ways to break down this data, and tell stories about it.\nConstructing a task-specific LM:\n\nA custom model was constructed using model distillation. First hand-labeling 3k labels, wrote a range of prompts, asked GPT-3.5 and -4 to extract noisy labels, and fine-tuned a set of open source models.\nThis was used to label a large corpus, far larger than we would have been able to do with the commercial models. And identified a larger set of clinical trials than included in some other sources, suggesting for instance the rate is not decreasing.\n\n\nDiscussion:\nQ: We know we face publication bias. Denominator of unpublished studies can be large. Do your results speak to that?\nA: In constructing the data, we tried to exclude reanalysis by multiple pubs. We don’t think publication bias is itself shifting over this time frame, in a way that would change the trends we observed.\nQ: You reflected on implications for research. What are the implications for reporting guidelines, at the reporting stage?\nA: A lot of people are thinking about policy here. Two strands: since 2007, all sponsors have to register their studies; since 2017, every sponsor under the FDA auspices has to report results. The FDA has not yet imposed penalties however for non-compliance. The FDAAA Trials Tracker tracks how much money the FDA could have collected had they enforced existing policy and listed fines.\nQ: User request: as the first person to fork your github repo, can you add the NCT Number?\nA: Yes, if we’ve extracted it we can. (ed: short and sweet!)"
  },
  {
    "objectID": "events/2024-technical-working-group/index.html#comparative-nlp-methods",
    "href": "events/2024-technical-working-group/index.html#comparative-nlp-methods",
    "title": "2024 Technical Working Group meeting",
    "section": "10:45 Comparative NLP Methods",
    "text": "10:45 Comparative NLP Methods\n\nTracing the Flow of Knowledge From Science to Technology\n\nDietmar Harhoff, Michael E. Rose, Mainak Ghosh, Sebastian Erhardt, Erik Buunk (Max Planck Institute for Innovation and Competition)\nThis is about LLMs for patents and science, working through some traditional challenges with the benefit of a model.\nEarly models e.g. BERT didn’t have all terms related to horses. So you would miss some horse-related patents or research. Then came Pat-SPECTER (fine-tuning SPECTER on pats) and Pub-PaECTER (fine-tuning PaECTER on publications), drawing on Semantic Scholar.\nThis project created a ‘racing ground’ : for a given patent, rank 30 other publications by similarity. 1000 randomly-selected patents, 5 cited pubs, 25 non-cited pubs. SPECTER and Pat-SPECTER performed well.\nApplications: separate patent-paper pairs from patent-paper citations, predict patent-paaper pairs, prior art search for earlier pubs. Making use of logic-mill.net and existing databases of works.\nYou can see the latest examples at logic-mill, and our huggingface repo.\nDiscussion:\nQ: People used to use GROBID to extract data like this. Can I use LLMs for this now?\nA: It can help. We need an English abstract to do it. So if you have a Springer article, which doesn’t share abstracts, it’s harder. The next gen of logic-mill will add Scopus abstracts.\n\n\n\nPatent Text and Long-Run Innovation Dynamics\n\nIna Ganguli (UMass Amherst, NBER), Jeffrey Lin, Vitaly Meursault (Federal Reserve Bank of Philadelphia), Nicholas F. Reynolds (University of Essex)\nHere are two graphs over two centuries showing “evolution of similarity”, using the same conceptual measure of similarity but different ways of assigning models to text (GTE vs TF-IDF):\n\nInstead: try choosing a model using validation tasks. A handful of cases that can serve as a gold standard (we saw examples earlier today). We can start with patent-interference cases, and look for complementary tests.\n3 validation tasks: - Patent Interference (we are very excited about this) - Human validation (economists should be doing much more of this!) - Classification\nPerformance: PaECTER, GTE, and S-BERT do best on different tasks. Pre-BERT models aren’t competitive, but can be more interpretable. The meta-model of ‘using validation tasks’ is a clear winner, but the specific models used has no clear winner. (and may lead to different conclusions)\nDiscussion:\n\nQ: I would expect these graphs to be smoother, given the size of the corpus; what does it mean when there are jumps over the course of a year?"
  },
  {
    "objectID": "events/2024-technical-working-group/index.html#global-patent-data",
    "href": "events/2024-technical-working-group/index.html#global-patent-data",
    "title": "2024 Technical Working Group meeting",
    "section": "11:45 Global Patent Data",
    "text": "11:45 Global Patent Data\n\nA New Database of Indian Patents\n\nNishant Chadha (Indian School of Business), Satyaki Chakravarty (Universita Cattolica del Sacro Cuore), Piyasha Majumdar (India Development Foundation)\nWe compile a patent-location database, using the database of inventors and a post code for 85% of them.\nYou get a status page of where each application is in its process. And you can use this to render a county-level map.\nPatents filed per region:\n\nPatents filed per sector:\n\nDiscussion:\nProblems: authors IPs are sometimes blocked by the government; and they need a bigger machine.\nQ: You said you renew patents every year. Is that just bureaucracy?\nA: It’s very cheap, you just tell someone to renew it for the next year. Some are not renewed. Renewal is studied more in the US, less in India to date.\nComment: Really unfortunate it’s not on PatStat b/c we don’t have the families as a result. There is priority data, but these samples don’t have a priority date. (only 60% have one) Numbers are messy, they take the original #s from offices that have thousands of variations. But we could clean that to get priority information.\nQ: About pharmaceutical research — After TRIPS, will patenting strategies change b/c jurisdiction specific distinctions about what is eligible will change? Chem and bio markets are interesting, India allows some drugs there first.\nQ: Is it possible to link clinical trial databases also? From India drug approval\nA: I don’t know where to find those. If you have that info, it would be another big task to do.\n\n\n\nCreating the China Patent Dataset\n\nJosh Lerner (Harvard, NBER), Namrata Narain (Harvard), Dimitris Papanikolaou (Northwestern, NBER), Amit Seru (Stanford, NBER)\nPresenting a new China patent dataset, tracking the growth in patenting there and its implications for studying innovation.\nThere are prominent examples of product that could have been foreseen or predicted by watching the growth of patents in certain areas. For instance a hypersonic missile that seemed to have caught US military by surprise, where there had been years of extremely high rates of patenting hypersonic technologies.\n\nWe hope to go live with this database next year. It includes all patents, whether granted or not, from many sources: leading to 16M patents after cleaning and deduping, with translated assignee names, tags, and non-cite measures of patent quality. It needs TLC before turning it over for full public use. Trying to resolve links to classifications of critical technologies, to identify relative positioning of US and Chinese industries over time.\nDiscussion:\nQ: Does your Chinese utility patent analysis distinguish between invention patents and utility model patents?\nA: Yes. That’s the first filter. What they call “utility patents” are the second-class ones in China, to make things confusing. We in the interest of simplicity have focused on their top-class patents, not on their second-tier patents.\nQ: Do you look at propensity to file in the US?\nA: In process. We’ve looked at it within critical-tech contexts as well. We want to know whether, as econ theories would predict, that the best patents per our metric are more likely to be cross-patented. With a caveat about secrecy in some cases.\nQ: Did you try to validate against Patsnap?\nA: We pursued that early on: whether commercial or semi-commercial databases out there should be used. We had a couple concerns. We wanted to make something that is fully public, open and unencumbered by licensing requirements (such as PatStat and Google Patents). And felt that many of these commercial tools were mainly deriving the information they offered from public data.\nQ: Foreign investment into the chinese economy has declined sharply since 2021. Do you see similar contraction in patenting? Do recent shifts in VC investment change what you’re seeing?\nA: We’ve been thinking more about constructing the dataset in the past 18mo. But the general thing one hears from the vc community is the environment has moved from a system that mirrored the US, to one where that has dried up considerably and most money comes from the Chinese government, with strings attached. A: Some of the changes in 2018 which led to many funders departing (specific to US funding) we should be able to trace in our data.\nComment: It would be interesting for policymakers if there were a study on the impact of China’s Technology Import and Export Administration Regulations (TIER), which allowed China to capture US technology.\n\n\n\nA Novel Dataset for Historical Innovation Studies: Linking USPTO Patents and US Census Data from 1850 to 1940\n\nZenne Hellinga (Utrecht University), Jay Praka. Nagar (Duke University), Stefano Breschi (Bocconi University), Andrea Morrison (University of Pavia), Gianluca Tarasconi (IPQuants)\nThis dataset is a work in progress, we are happy to release it and your feedback is welcome! Recently more papers have looked at historical patents to see long-term trends, but lack information on inventor backgrounds: families, occupation, birthplace. Some studies have linked inventors to census data, but these vary greatly in matching strategy, coverage [and granularity].\nThis is an effort to make a publicly available linked dataset with maximal coverage, and compare it to existing datasets. Starting with Google Patents, Census (trying to link across census decades)…\n\n\n1:15 pm — Lunch !\n\nOriginal content published on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)"
  },
  {
    "objectID": "events/2023-technical-working-group/index.html",
    "href": "events/2023-technical-working-group/index.html",
    "title": "2023 Technical Working Group Meeting",
    "section": "",
    "text": "December 1-2, Cambridge MA | Agenda (NBER) | Youtube recording"
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#matching-scientists-and-inventors",
    "href": "events/2023-technical-working-group/index.html#matching-scientists-and-inventors",
    "title": "2023 Technical Working Group Meeting",
    "section": "Matching Scientists and Inventors",
    "text": "Matching Scientists and Inventors\nLee Owen Fleming, University of California, Berkeley Matt Marx, Cornell University and NBER Emma Scharfmann, University of California, Berkeley\nDiscussion:\nIf anyone knows about the bump of Chemistry papers and gatekeepers around 2010, let me know. A: That’s an OpenAlex error in using the date of publication, not date of invention, that’s the date that lots of documents were published online.\nWe use the term ‘gatekeepers’ for someone who both publishes and patents. Also ‘scientist-inventor’. Comment: Maybe not a good term for you. Esp seeing the geographic patterns; opening slide makes me think of centrality and eigenvectors; these aren’t gatekeepers of info flow. It also feels normative.\nQ: For many East Asian countries, there’s an oversupply of grad students, just part of the culture that you’ll overeducate a bit [then students will go to firms?]\nA: I never connected that to the asian angle until yesterday; that makes a lot of sense.\nQ: You started from paper-patent pairs where Matt started. I’m guessing that the vast majority of output is not actually such pairs, it’s people doing both. Have you looked at that at all?\nA: That’s my intuition also, but haven’t looked.\nQ: You have the # of patents and papers, maybe you can classify based on the distribution? Some write a lot and patent once, some patent a lot and write once. Impact of each one?\nA: One slide that didn’t make it is a pie chart: gatekeepers seem to be prolific scientists; more than 50 papers. A: Old work on university patenting shows that’s true. Profs who patent are on average the most productive.\nQ: In general you’re looking at a slew of papers/patents by the same person?\nA: We start with patent/paper pairs, then look at their ORCID papers to expand our training set. That’s where we get model numbers. But we didn’t look at accuracy after we’re done with clustering, which is a headache.\nAdam: Thanks all! Looking forward to working with the data when it comes out next summer."
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#the-commercial-potential-of-science-its-realization-evidence-from-a-measure-using-an-llm",
    "href": "events/2023-technical-working-group/index.html#the-commercial-potential-of-science-its-realization-evidence-from-a-measure-using-an-llm",
    "title": "2023 Technical Working Group Meeting",
    "section": "The Commercial Potential of Science & its Realization (Evidence from a Measure Using an LLM)",
    "text": "The Commercial Potential of Science & its Realization (Evidence from a Measure Using an LLM)\nSharique Hasan, Duke University Roger Masclans Armengol, Duke University Wesley M. Cohen, Duke University and NBER\nWe’re building here on the work and data of people in this room, particularly Reliance on Science; thanks for this!\nOur work studies ex ante commercial potential. We want to measure commercial potential w/ ML, making forward looking predictions given data we have now.\nWe realize that commercial potential is a boogeyman. Some of the questions we have: Are there gaps or biases against women or minorities from certain regions, or specific regions where research is published?\n\nOutcome: scientific finding, cited in a patent that is renewed.\nPredictor: knowledge contained in article abstracts alone.\nMethod: relying on SciBERT embeddings for abstracts, using NN with predictors as embeddings. We also use two secondary measures of potential: academic cites vs patent cites, and social impact.\n\nWe develop one model per year, using citations up the year prior to the prediction year. This provided rolling predictions.\nExample: Nobel prize research papers…\nOur model accuracy was around .74 (AUROC and Accuracy)\nTo test this outside of our training set, we started with invention disclosure and outcomes from a TTO at a leading research uni. Matched inventions to articles they rely on. From the resulting set of 96k pubs we could match 13k pubs to 2700 inventions, w/ a median of 2 papers per invention.\nThe model picks up specifics from the article that suggest future use in patents independent of things like h-index and fixed effect for field and year.\nWe used the model to estimate whether it gets disclosed, cited in a patent, &c.\nConditional on disclosure, we looked at whether there is investment, patents filed, licensed, &c. Conditional on investment, we looked at whether this model’s predictions continued to predict future stages of commercial success.\nWe also compared the impact of TTO involvement., and compared across different institutions. About 60% of the variation of patent citations pf papers can be explained by mean ex-ante commercial potential for that institution.\nNoting limitations: many contributions reach the market without associated patents. This may only partially capture potential due to indirect paths to commercialization. Long time horizons are often required before scientific contributions are embodied in new products.\nQ: Do public university limitations on self-funding limit the potential that would be illustrated here? They may have high potential science but are restricted (via TTO options) in how they can make profitable investments. (from the UC perspective)\nA: That’s a great question, we’d like to use our model to consider this.\nQ: Maybe you can look at attributes that characterize good ideas that haven’t been commercialized. That’s the question really on the table — what is undiscovered, what characteristics are undiscovered?\nA: We’re looking more generally at determinants of what we call the “realization gap”.\nQ: Long ago I made a credit-scoring algorithm re: whether startups would fail within 4 years. I talked to a lot of banks and partners continued to work on this after. The AUC was just like yours. This algorithm didn’t commercialize. Our problem was: even though AUC is 0.74, what’s the value of that signal? If it’s too noisy, even if it’s fairly good, that doesn’t help the user. Thoughts on what success you need for this to get used?\nA: Good question. Also how does this compare to human evaluators’ AUC? We can get away with this for a research exercise.\nQ: I love the scalability here, you can see the whole field. How does this work on subfields? Compare to fine-graining subfields, where you have easy breakdown by schools, topic area, &c. Are there fields where this is a significant improvement?\nA: We are thinking about this. We’ve done field-specific models; you get some extra juice; in some you can get clear separation. Physics, clear difference between basic physics and quantum.\nQ: Did you look qualitatively at the embeddings to see how much the model is picking up on language suggesting the author is thinking about patenting or preparing for a patent? Which may be separable from the commercial potential of the idea.\nA: We looked at whether asking ChatGPT to make abstracts “sound more like a patent” affected the model prediction; it only had 2-3% of an effect. But things that did have an effect were: indications of tackling a big vs narrow problem, something likely to affect a lot of people, subjects related to a commercial product or service. See note above re: theory vs applied physics.\nQ: What about more path-breaking innovations? Things w/ long gestation periods?\nQ: Did you consider whether you’re picking up on terms indicating where the field is going, so that those mentioning that are more likely to be cited in patents? Could this lead to the high predictions for papers that were later Nobel Prizes?\nA: That’s interesting, want to think it through clearly. Possibly\nQ: This data will be public, yes?\nA: Yes, soon!"
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#new-facts-and-data-about-professors-and-their-research",
    "href": "events/2023-technical-working-group/index.html#new-facts-and-data-about-professors-and-their-research",
    "title": "2023 Technical Working Group Meeting",
    "section": "New Facts and Data about Professors and their Research",
    "text": "New Facts and Data about Professors and their Research\nKyle R. Myers, Harvard University Wei Yang Tham, Harvard University\nContext: Discourse on “Science! Does it work, is it broken? Will we ever know?” Since we don’t have prices, or traditional labor and capital, we have a wide range of inputs and outputs and payoffs and preferences. So we make lots of assumptions about these things to analyze them.\nChallenge: databases we’re using were created for scientists advancing science, not to evaluate or study science. We want to subjectively measure un-observable things, focus on breadth over depth, across fields. Consider this a potpourri of correlations. When you need a motivating fact, hopefully this dataset will have something for you.\n\nData selection: we emailed a subset of 260k people to get data.\n\n~ ~\n\n\nLots of areas to explore:\n\nMuch more earnings variation is within-field compared to across-fields\nInstitutions, ranks, tasks and sources are quite important for earnings\nStandard meta-sci, used research output is not very important for earnings\nPubls-per-year is a mediocre proxy for pubs-per-research-hour\nResearch risk beliefs: fundraising, personal risks, and generating theories\nLife-cycle changes in research inputs and outputs, but not audiences\n‘Edisons’ tend to take more personal risks and earn more than ‘Bohrs’\n\n\n6:45 pm Dinner"
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#index-and-validation-datasets",
    "href": "events/2023-technical-working-group/index.html#index-and-validation-datasets",
    "title": "2023 Technical Working Group Meeting",
    "section": "Index and Validation Datasets",
    "text": "Index and Validation Datasets\nAgnes Cameron, Knowledge Futures\nThe I³ open innovation data index turns 2 this year. You can see and browse it at iiindex.org, and add new data or edit metadata directly on github.\nValidation datasets are tools in their own right, and we’ve started to gather them. Please publish yours. Many papers have open data but don’t publish their validation data. Talking to authors, people either feel they are very valuable and are wary of publishing, or on the other end of the spectrum don’t think they would be useful to anyone else.\nExisting models for this in machine learning are robust: in part because dataset creation and validation are a central feature of sharing research, and everyone appreciates the release of validated datasets and the chance to reuse them. So there is a lot of infrastructure for this: 🤗, kaggle, papers with code. HuggingFace in particular shows you which tasks projects and models are used for.\nCurrent gaps: projects that make heavy use of validation data and rarely publish those datasets. How can we credit and promote what’s happening? What validation data do we want to bring into being? Contributions welcome!\nQ: Do we have a sense of how many people use validation datasets vs other datasets? [other than their own]\nA: This comes into its own once there is a norm around sharing and reusing them. Rarely considered something to credit. People currently just use it in the construction of new datasets, more than in reevaluating existing ones or shared between projects.\nQ: Good to compare the ML models of credit for naming such things. But credit in CS has often been different from other fields. We need to think about how to adapt to the field norms. For instance: creating a dataset paper alongside the dataset helps [for NBER data]; something like that here could be important for this community."
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#logic-mill---a-knowledge-navigation-system",
    "href": "events/2023-technical-working-group/index.html#logic-mill---a-knowledge-navigation-system",
    "title": "2023 Technical Working Group Meeting",
    "section": "Logic Mill - A Knowledge Navigation System",
    "text": "Logic Mill - A Knowledge Navigation System\nErik Buunk, Max Planck Institute for Innovation and Competition Sebastian Erhardt, Max Planck Institute for Innovation and Competition Mainak Gosh, Max Planck Institute for Innovation and Competition Dietmar Harhoff, Max Planck Institute for Innovation and Competition Michael E. Rose, Max Planck Institute for Innovation and Competition\nCurrent status of logic-mill.net : Beta w/ 8 API functions, 228M documents (200M from S2). 130 users from 30 institutions.\nRoad map: improving our language model, moving beyond our current 512-token limit, updating/expanding data sources (to include Open Alex, and PATSTAT). We also want to add API functionality and offer precomputed datasets.\nQ: What about providing pairwise similarities for all ~50Q pairs?\nA: [That might be hard.]\nQ: what does it take to compile this, technically?\nA: we need to store a lot of vectors in memory, we have &gt; 1TB of RAM in our HPC. Thanks to Max Planck for this.\nQ: Have you segmented the overall corpus and found any interesting subsets with shared structure?\nA: I’ve looked at this a lot, for instance we looked at the patent families of single companies, including large ones like Siemens. There are definitely useful clusters that can be seen there with this tool; we haven’t done something like this across the entire corpus. Algorithms for this tend to take additional memory so we’d need even more compute."
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#discern-2.0-extending-and-enhancing-the-discern-dataset",
    "href": "events/2023-technical-working-group/index.html#discern-2.0-extending-and-enhancing-the-discern-dataset",
    "title": "2023 Technical Working Group Meeting",
    "section": "DISCERN 2.0: Extending and Enhancing the DISCERN Dataset",
    "text": "DISCERN 2.0: Extending and Enhancing the DISCERN Dataset\nAshish Arora, Duke University and NBER Sharon Belenzon, Duke University and NBER Larisa C. Cioaca, Duke University Lia Sheer, Tel-Aviv University Dror Shvadron, Fuqua School of Business\nUpdates in 2.0: extended coverage to 2021, added R&D firms that don’t patent. Moved from ORBIS to SEC filings, from PATSTAT to PatentsView, added patent-level reassignments and pre-grant applications. Moved from Web of Science to OpenAlex\nWe’ve improved our matching algorithms and expanded the doc-family by moving to OpenAlex. We used raw affiliation strings from the PDFs (81M uniques!) and not the normalized data in OA — for data quality reasons?\nWe’re using gen AI models every day, tried to feed these strings into an LLM to get out the firm name. We took the raw string, asked a model to guess the firm, and get back a clean name to aggregate. We tried the same for entity resolution.\nWe’re using LLAMA and vLLM for this clean-up. cascade of cleanup steps for OpenAlex matching.\nQ: Can you ask OpenAlex to do that [themselves]?\nAudience to heckler: no, but you can :)\nQ: You mention looking at ownership changes. Are you looking at other things such as name changes, across renewals, and publications following assignment?\nQ: Do you also track sales, as part of tracking ownership changes?\nA: We do look at that. [to the extend data exists] Adam: USPTO asks firms to report, but it’s not obligatory. I don’t know if we have estiamtes of how complete the reassignment file is. Many of us have said for years the law should be changed so that you have to tell the PTO for assignment to be enforceable. I’ve said publicly that most of the things we argue about have two sides, here there’s only one thing to do.\nQ: I wonder about the reliability of the LLM system you used. That seems like it should depend on the quality of data used; how did you check its validity?\nA: We did look at it, can discuss it more after.\nQ: You said you’re looking at pre-grant pubs as well:\n1) assignment is often missing for ungranted applications, how do you think about it? 2) if you look at European pairs, can you pick up that data anyway? A: Interesting idea, thanks\n\n10:00 am — Patenting Firms"
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#improving-patent-assignee-firm-bridge-with-web-search-results",
    "href": "events/2023-technical-working-group/index.html#improving-patent-assignee-firm-bridge-with-web-search-results",
    "title": "2023 Technical Working Group Meeting",
    "section": "Improving Patent Assignee-Firm Bridge with Web Search Results",
    "text": "Improving Patent Assignee-Firm Bridge with Web Search Results\nYuheng Ding, The World Bank Karam Jo, Korea Development Institute Seula Kim, Princeton University\nFirm innovation is a major source of creative destruction and economic growth. We constructed a longitudinal patent-assignee-firm bridge between assignees and firms, using administrative data from Census. I’ll talk about data sources, matching methodology, and a practical example.\nWe link the USPTO to the Business Register and Longituinal Business Database. Stages: name standardization, fuzzy-name matching, patent-firm crosswalk (a “search-aided bridge” search within USPTO + extraction from internet searches) Search-aided matching accounts for 4-8.5% of total assignee and patent matches, provides a more stable bridge over a longer horizon, and can help study non-public firms that aren’t in the PTO data.\nExample: looking at impact of Chinese competition on firm innovation. We were able to use the bridge to help match with other sources like young firm data.\nQ: Are there any characteristics of the new matches you were able to make?\nA: Fuzzy name matching only fixes small character shifts. But significantly different formats, such as “IBM Corp” and “International Business Machines corp” benefit from this bridge.\nQ: Any idea what fraction are private firms?\nA: Not sure exactly, but one eample might be young firms that wouldn’t be in the public firms list. These are ~30% of the total population:\nQ: How does accuracy change over time? I can imagine internet search is more helpful recently than for firms in the 1980s.\nA: We do look at this; nothing published yet, but we haven’t considered working this into the overal stats about matching-improvement\nQ: I understand this is set up for people who can access it through the Census system. Have you thought about a version of this that could be used by anyone online? A scaled-down version you could release publicly?\nA: Absolutely. There’s a version of matched assignees that is totally public, that could be published. Q: Aside form compustat firms, what about small firms? to have names standardized within patent data. That would be valuable, I think. PatentsView has done some of this for names disambig. But this seems better (esp for private firms). You might want to talk w/ someone in the office of the chief economist, which owns PatentsView, to incorporate your better assignee-name disambig into their public data.\nA: Great idea.\nQ: (AT) a) Since you’re working in the Census Bureau, what’s the relationship b/t your work with the BR and what others are doing in CES and Census?\nA: Work by Nathan and others starts at 2000, trinagulating by inventors. He said he’s planning to accomodate all these methodologies, collecting existing bridges over multiple periods. That’s in progress within Census. b) impressive to see what you’re doing linking patent data to companies. Now we have lots of different versions around: DISCERN, PTO, NETS (nat’l time-series database) w/ D&B. It would be nice to know to what degree these datasets agree with one another about linkages. As this group wants to reduce duplication, when we have many variateis of the same linkage data going on, how can we support comparison across them? A: That’s certainly part of the I3 Index, Agnes can speak to how to facilitate that comparison. It’s hard for dataset-generators who can’t access/read the Census alternatives. c) You mentioned patent applications, that word has a specific meeting : a company might file 10 applications at one moment. Then over time, some are granted/allowed and become visible, some remain pending, often invisible but could be in pre-grant data, and some are abandoned. Those may never show up in public data depending on if it happens before 18 mo after the publication date. I think you mean when you say ‘applications’, “granted patents”. We’ve tried to link this via the lawyers, as lawyers are consistent over time for a company; can be used to confirm that something abandoned is from a given firm."
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#the-government-patent-register-a-new-lens-on-historical-u.s.-government-funded-patenting",
    "href": "events/2023-technical-working-group/index.html#the-government-patent-register-a-new-lens-on-historical-u.s.-government-funded-patenting",
    "title": "2023 Technical Working Group Meeting",
    "section": "The Government Patent Register: A New Lens on Historical U.S. Government-Funded Patenting",
    "text": "The Government Patent Register: A New Lens on Historical U.S. Government-Funded Patenting\nDaniel P. Gross, Duke University and NBER Bhaven N. Sampat, Arizona State University and NBER\nWorld War II was the first time we had a shock of government funding. A proliferation of funding agencies included PHS, DoD, AEC, NSF. We looked at this; ideally would have precise geographical and field division of funding.\nWe looked at government-funded patenting: traditional measures include - assignment to a government agency; those with a gov. interest statement, which links it back to a grant or contract. Those don’t work well historically, so we tracked down another: the government patent register.\nBayh-Dole in 1981 created a uniform license policy & required gov interest statements. …\nWe scanned and digitized the Register; at some point there’s a transition to amodern electronic register. Our records go through mid-1990s. Based on this, the gov share of patents peaks during WWII, mostly DoD, then declines. [Ex: Fermi patents]\nOne of the best sources for patent citations to science is the Fleming, et al. dataset; there’s also material since the 70s that isn’t in the register but is in the Fleming dataset, and we’re still looking into what led to that shift.\nThe way forward: we want to link the Register, work that Matt and Lee have done, and providing a modern register that stitches them together and irons out the creases. We’ve also thought about using words in patents, to see how those relate to different regimes.\nUses: as historical indicator of pub vs private R&D. but patents != R&D… As control for evaluations of specific changes, especially where correlated w/ DoD funding. Evaluating “title” vs “license” policies, exploiting all the variation before Bayh-Dole.\nDiscussion:\nQ: How big a role does gov funding play in innovation direction for major new paradigms and breakthroughs? E.g. recent COVID vaccines? iPhone tech based on gov-funded research?\nA: good use case for us and others!\nQ: Do you have a measure, citations or other, to show whether gov funded patents are more important than private, by industry / by department, per patent or sectorally?\nA: We’d like to go beyond citations here.\nQ: Is the stitching together available yet? Can we email you?\nA: It’s available, we’re still working on stitching for a few months but will share it with you.\nQ: Do you have a sense of the connection b/t these patents and the subsequent creation of institutes like Stanford Engineering, pushing a new frontier?\nA: We do; we’re getting into the creation of new fields, in medical contexts, not using patent data. That’s something we’re pursuing. It’s a longer answer, but happy to talk about that after.\nQ: Niggling Q - you posted the Roosevelt exec order but also showed data from before…\nA: They backfilled — the agencies did. Great question, and relates to another point I didn’t make: agencies did keep records. I don’t have the total # in the Register over time, it’s small before WWII. How reliably records were kept I don’t know; there wan’t much funding of R&D and debates then were about context where someone in Ag had their own invention, intramurally; who gets the rights to that. Those are USC 266 patents. Q: Might be useful to see which agencies did and didn’t backfill.\nQ: How well do people comply with requirements to report back?\nA: There are requirements to report back to agencies; we didn’t get in too detail into complaince, but we coulde explore that with modern data."
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#startup-patenting",
    "href": "events/2023-technical-working-group/index.html#startup-patenting",
    "title": "2023 Technical Working Group Meeting",
    "section": "Startup Patenting",
    "text": "Startup Patenting\nMichael Ewens, Columbia University and NBER Matt Marx, Cornell University and NBER\n\nIf you asked 10 people on the street, who was more responsible for innovation: startups or big firms, they’d all say startups. But we don’t have a lot of evidence on this point. What are our public options for matching startups to patents? (for those w/o Census data)\n\nPatEx has a small/micro firm indicator, but size isn’t a good proxy for age. Still nearly impossible to find new ventures that hold patents. You can download a Crunchbase-2013 snapshot, but don’t have firm founding year for most firms. Even DISCERN only has year it was publicly listed.\n\n\nWe use OpenCorporates: yet another Sloan project, a B corp that has solved the conundrum of making data sustainable. (The have a successful model: free web searches for a certain amount, but pay to be able to harvest.) First we try a loose API search. Insisting on an exact match for short names and common names. We looked at 190k assignees, got results from 160k, went through scoring+cleaning. We penalized if it dissolved long before the 1st patent, or incorporated too long after.\n\n\nWe also used some PitchBook data (which we can’t give out; can only give a flag saying ‘this firm raised VC’)\n\n\nCurrent status (Beta, foundingpatents.com): 142k assignees found. That’s 85% of patents, 73% of assignees. Not as good as Census, but fully open. — 135k from OC, 2k from Discern 1.0, 4k from PitchBook — PV assigneeID from 2022, OC ID + founding yr / confidence score, + VC / confidence score\nFindings: Young vs old firms: more likely to be cited, and cited by a larger range of patent classes. Can I say these are better patents? (A: no…) Young vs (small, not young): fewer cites to science. There’s selection bias: all old firms used to be young. So say we only look at firms that stop patenting after 3-8y. They peak early in # and in novelty of patents\nDo young firms shape new industries? There’s clear correlation. VC-backed firms are about 1/3 of all. There’s no difference in novelty (compared to non-VC funding). But they don’t cite science as often and don’t get cited as often.\n“Burden of knowledge” — is innovation getting harder to find? People staying in PhD programs longer? Do we see this in patent assignees (in firm age)? No. First patent assignment is coming earlier. But they’re also hiring older inventors, and people who have patented in more classes before they are hired.\nNext Steps: international assignees; work with the updated patent-paper pairs dataet, mentioned over the summer, which is now updated to 2022, fully moved to OpenAlex: at the new relianceonscience.org\nDiscussion:\nQ: Which comes first, good patent or startup? Do good ideas get funding b/c the idea is good and patented, or do they patent after starting up?\nA: Unclear. Maybe both? See related work on non-startup firms.\nQ: Any anomalies you’ve found in there?\nA: The dataset is now online, you’ll see the first patents are sometimes in -5 years. There are a lot of anomalies; we find historical assignees harder to get.\nQ: Compare this to the Startup Cartography work?\nA: I think they also build on OpenCorporates, but we could get data directly.\nQ: if time to first patent is declining, but inventor age is increasing, does that say anything about time to invent? Is it partly that they delay founding and patent fast once they start up?\nA: That’s a very compelling idea. We could look at whether inventors come from academia, or leave a firm and do this and decide to do it as a startup?\nQ: Cf. the Graham/Samuelson survey from 2008: if you just use startup assignees, you miss out on founders who had patents that weren’t assigned to the firm.\nA: Aha!\nQ: Interesting you’re working w. PitchBook. We’re doing something mixing PitchBook, Crunchbase, Capital IQ — and found less than 20% of firms in dataset that showed up in more than one source. We matched to NETS which is great, 80% match there. But be cautious about relying on just one of these.\n\n11:30 - 11:45 Break"
  },
  {
    "objectID": "events/2023-technical-working-group/index.html#i³-fellows-presentations",
    "href": "events/2023-technical-working-group/index.html#i³-fellows-presentations",
    "title": "2023 Technical Working Group Meeting",
    "section": "I³ Fellows presentations!",
    "text": "I³ Fellows presentations!\nPatents or Defensive Disclosures? — Bernhard Ganglmair, Univ. of Mannheim Using Pydrad — Bernardo Dionisi, Duke University Linking Scientific Articles to Media Mentions — Saqib Mumtaz, Berkeley Statistical Evidence from Clinical Trials — Maya Durvasula, Stanford\n\nPatents or Defensive Disclosures? Bernhard Ganglmair\nDo patents tell the whole story? How do defensive disclosures relate to patents? Learn CPC classes for disclosures with transfer learning, find similar patents.\nChallenges: Heterogeneity (no given format) + Domain differences (between patents and disclosures). We used an NLP pipeline with Llama2 to help generate abstracts to reduce heterogeneity; and an elaastic search to support domaina daptation to reduce differences.\nWe want to build a model good at classifying [patents] but bad at distinguishing b/t disclosures and patents. Similar to DANN (2015) Our main contribution will be our general pipeline to map texts into CPC space; aiming for two papers: one descriptive on patents vs disclosures, one analytic on the effect of changes in patentability.\nQuestions for the audience: can’t share the raw data yet. If you have something we can test this on, where you want CPC classes, let us know and we’ll try to do it, and that could be published on the I3 site / in the Index.\nDiscussion: Q: Why do people use disclosures vs publication (scholarship, &c)? Can you compare disclosures to other publication, in various fields?\nA: It’s easier; don’t pay as much. $120 vs $1k+, no referees, just a single invention or idea rather than a writeup. But yes, could be an extension\n\n\n\nUsing Pydrad Bernardo Dionisi\nHow do we access data? Some of us are still using flatfiles :) Pydrad is a python library that lets you pull in a range of common large datasets: Reliance on Science, Open FDA, PatentsView, &c. You can import the library and then reference the datsets by name.\nRegistering and integrating a dataset is easiest if its in a repository like Zenodo with a clean API. Aiming to integrate registration with the I3 Index once it is online (not quite yet).\n\n\n\nLinking Scientific Articles to Media Mentions Saqib Mumtaz\nMany researchers share updates at conferences and public talks, and there’s a media landscape dedicated to promoting science; this is understudied compared to paper publication and patents.\nWe started with EurekaAlert data, then linked it to author data on OpenAlex. First pass matching is 58%. Some of this is from date errors in OpenAlex. Using dates from CrossRef increases match rate to over 80%.\nQ: There’s work on hype in scientific publications, and Qs around gender dynamics, and characterizations of uncertainty (does confident science get more attention than that which exposes its uncertainty?) Have you looked at these aspects?\nQ: Are things more likely to be licensed if they get press releases?\nA: Certainly things that are licensed get more pess attention; I haven’t seen results that are too closely linked [for novel discoveries?], but the further you are from the source of [the science], the more a press release helps.\n\n\n\nLLMs as Research Assistants: constructing a corpus of medical evidence Maya Durvasula, w/ Sabri Eyuboglu and David Ritzwoller\nExcited to share this work! Recently we’ve been using clinical trials as measures of innovation: how firms respond to gov policy and prioritize investments. But just as unweighted patent counts seems to leave information on the table, unweighted trial counts miss out on their details: trials are standardized, for quantitative output; studies can be more or less well designed and more or less successful.\nWe combine scientific pubs, clinicaltrials.gov records, and FDA approvals. Most of PubMed doesn’t include clinical trials; we flag abstracts by keyword, and look at NLM categories, to get 1.8M abstracts. Colleagues made us a nice interface speeding hand-labelling by 5-10x, to build meaningful training data. Then we iteratively developed prompts for GPT-3 and GPT-4; final prompts got us down to 5% false negatives/positives. Trying a range of visually similar prompts improved the success rate by a factor of 4-5, esp with GPT-3. We also extracted 60k ‘noisy’ labels from each model.\nQ: “Why not use GPT-4 for everything?”\nA: This was quite expensive. It seems expensive for them as well, and not suitable for this sort of labelling at commercial scale. Also, chatGPT is a black box, and we’d like more visibility into their workings.\nWe chose LLaMa, Mistral, and Pythia; but got comparable performance from BERT directly. Fine-tuning w/ GPT-3 labels we could match perf of GPT-3 with open models. Fine-tuning w/ GPT-4 labels we could match perf of GPT-4!\nFinally, we tried a few version of the open models. BiomedBERT trained on PubMed, &c. These didn’t necessarily do better than off the shelf BERT.\nConclusions: we can use LLMs to get very close to hand labelling. Prompt design matters. Fine tuning let us beat the perf of proprietary models.\nNext Step: streamlining a workflow for label extraction, getting better statistical information, using that to reduce errors.\nQ: Have you talked to the NatLib of Medicine to update MESH tags in a similar way?\nA: They’ve been using algorithms to do that since 2022. Not this technique but they’re working towards something like this.\n\n1:00 pm — Lunch\n\nThanks for joining! For further questions or conversation, please join the I3 discussion list (i3-open). To register new datasets or validation datasets, see iiindex.org.\n\nOriginal content published on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)"
  },
  {
    "objectID": "events/2020-fall-workshops/index.html",
    "href": "events/2020-fall-workshops/index.html",
    "title": "I³ Fall Workshops 2020",
    "section": "",
    "text": "October - December 2020 | Virtual (Zoom)\nFormat: Five-part workshop series, Wednesdays 12:00-1:00 PM or 12:00-1:30 PM EDT"
  },
  {
    "objectID": "events/2020-fall-workshops/index.html#overview",
    "href": "events/2020-fall-workshops/index.html#overview",
    "title": "I³ Fall Workshops 2020",
    "section": "Overview",
    "text": "Overview\nDue to the COVID-19 pandemic, the Innovation Information Initiative replaced the traditional December in-person Technical Working Group meeting with a series of five virtual workshops. These sessions fostered dialogue among researchers exploring various dimensions of innovation metric construction.\nEach session featured 20-minute presentations by panelists followed by discussion periods. Recordings and detailed notes are available for individual sessions."
  },
  {
    "objectID": "events/2020-fall-workshops/index.html#workshop-sessions",
    "href": "events/2020-fall-workshops/index.html#workshop-sessions",
    "title": "I³ Fall Workshops 2020",
    "section": "Workshop Sessions",
    "text": "Workshop Sessions\n\nSession 1: Linguistics\nDate: October 28, 2020\nPanelists: - Nancy Kong - Jonathan Ashtor - Ryan Whalen\nFocus: Linguistic approaches to patent text analysis, natural language processing techniques for innovation metrics, and text-based patent classification methods.\n\n\n\nSession 2: Citation\nDate: November 4, 2020\nPanelists: - Matt Marx (Cornell/NBER) - Cyril Verluise - Osmat Jefferson\nFocus: Citation network analysis, patent-paper linkages, forward and backward citation patterns, and citation-based innovation metrics.\nTopics Covered: - Citation data quality and completeness - Cross-database citation matching - Science-technology knowledge flows - Citation-based impact measures\n\n\n\nSession 3: Geography\nDate: November 11, 2020\nPanelists: - Antonin Bergaud - Gabriele Cristelli\nFocus: Geographic disambiguation and location assignment for inventors, assignees, and institutions.\nKey Challenges: - Address standardization and geocoding - Inventor mobility tracking - Regional innovation systems analysis - Cross-border collaboration patterns\n\n\n\nSession 4: Gender\nDate: November 18, 2020\nPanelists: - Çağatay Bircan - Alenka Guzmán\nFocus: Gender identification methodologies, diversity in innovation, and gender-based analysis of patenting and publishing.\nDiscussion Topics: - Name-based gender inference methods - Accuracy and validation approaches - International naming conventions - Gender disparities in innovation - Non-binary considerations in classification\n\n\n\nSession 5: History\nDate: December 2, 2020\nPanelists: - Mike Andrews - Dan Gross (Duke/NBER) - Tania Babina (Columbia)\nFocus: Historical innovation data collection, digitization of historical records, and long-run innovation trends.\nTopics: - Historical patent data digitization - Archive access and data quality - Temporal consistency in metrics - Long-run innovation patterns - Connecting historical and modern datasets"
  },
  {
    "objectID": "events/2020-fall-workshops/index.html#key-themes",
    "href": "events/2020-fall-workshops/index.html#key-themes",
    "title": "I³ Fall Workshops 2020",
    "section": "Key Themes",
    "text": "Key Themes\nThe 2020 Fall Workshops explored fundamental challenges in innovation measurement:\n\nData Quality: Ensuring accuracy and consistency across datasets\nMethodology: Developing rigorous approaches to metric construction\nStandardization: Creating shared definitions and best practices\nValidation: Testing and verifying measurement approaches\nCross-cutting Issues: Addressing challenges that span multiple dimensions (e.g., geographic-gender interactions)"
  },
  {
    "objectID": "events/2020-fall-workshops/index.html#format-innovation",
    "href": "events/2020-fall-workshops/index.html#format-innovation",
    "title": "I³ Fall Workshops 2020",
    "section": "Format Innovation",
    "text": "Format Innovation\nThe virtual workshop series format proved effective for: - Focused, topic-specific discussions - Broader participation across geographies - More frequent community engagement - Accessible recordings for wider audience - Lower barriers to participation\nThis model influenced future I³ event planning and community engagement strategies."
  },
  {
    "objectID": "events/2020-fall-workshops/index.html#resources",
    "href": "events/2020-fall-workshops/index.html#resources",
    "title": "I³ Fall Workshops 2020",
    "section": "Resources",
    "text": "Resources\n\nFull Event Information\nI3 Discussion List\nIndividual session recordings and notes available on PubPub\nPrevious TWG meetings: 2019\nSubsequent meetings: 2021, 2022, 2023, 2024\n\n\nOriginal content published on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)"
  },
  {
    "objectID": "events.html",
    "href": "events.html",
    "title": "Events",
    "section": "",
    "text": "2025 Technical Working Group meeting\n\n\nDecember 2025 meeting of the I3 TWG\n\n\nTwo-day event featuring presentations on emerging tools and datasets for innovation research, including discussions of entrepreneurship databases, new product analysis…\n\n\n\nDec 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n2024 Technical Working Group meeting\n\n\nDecember 2024 meeting of the I3 TWG\n\n\nTwo-day event featuring presentations on emerging tools and datasets for innovation research, including discussions of entrepreneurship databases, new product analysis…\n\n\n\nDec 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n2023 Technical Working Group Meeting\n\n\nDecember 2023 meeting of the I3 TWG\n\n\nTechnical Working Group meeting held in Cambridge, MA. The agenda encompassed presentations on matching scientists to inventors, measuring commercial potential in science…\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nWinter 2022 Technical Working Group Meeting\n\n\nDecember 2022 meeting of the I3 TWG\n\n\nTwo-day event at NBER featuring presentations on patent-article corpus building, semantic matching datasets, mapping patents to technology standards, pharmaceutical Orange…\n\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021 Technical Working Group Meeting\n\n\nDecember 2021 meeting of the I3 TWG\n\n\nTwo-day event in Cambridge featuring the launch of OpenAlex and iiindex.org, alongside presentations on patent text analysis, firm technology portfolios, startup matching…\n\n\n\nDec 3, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\nI³ Fall Workshops 2020\n\n\nVirtual workshop series replacing the December TWG meeting\n\n\nFive-part virtual workshop series held Wednesdays featuring panels on linguistics, citation, geography, gender, and history dimensions of innovation metrics construction.…\n\n\n\nOct 28, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n2019 Technical Working Group Meeting\n\n\nInaugural December 2019 meeting of the I3 TWG\n\n\nInaugural two-day meeting in Cambridge featuring initial data construction projects including prior art metrics, Public Innovation Dataverse, patent-science references, and…\n\n\n\nDec 6, 2019\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "governance.html",
    "href": "governance.html",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "Version 1.0 | Effective Date: [Insert Date]\n\n\nThe Innovation Information Initiative (i3) is a global community of economists and innovation scholars dedicated to building open, interoperable datasets to advance research on science, technology, innovation, and entrepreneurship. i3 develops high-quality public datasets, shares methodological best practices, and coordinates research infrastructure to democratize access to innovation research data.\n\n\n\n\n\nThe Steering Committee is the primary governing body of i3, responsible for setting strategic direction and making major organizational decisions. It comprises five to seven members serving staggered three-year terms, providing continuity while enabling the regular introduction of new perspectives. Decisions are made by simple majority vote of members present at a duly constituted meeting. The Steering Committee approves annual budgets, expenditures above $5,000, changes to governance policies, and the admission of new Steering Committee members.\nDecision-Making: - Decisions require a simple majority vote - Quorum: At least 50% of committee members must be present - Meetings held at least semiannually\n\n\n\nThe Project Lead manages day-to-day operations, maintains technical infrastructure, and serves as the primary point of contact for i3. The Project Lead is authorized to approve expenditures under $5,000 without prior Steering Committee approval and is responsible for preparing agendas for Steering Committee meetings, maintaining records of decisions, and reporting regularly to the Steering Committee on operational matters.\n\n\n\nTopic-specific project groups may be established by the Steering Committee or community members to focus on particular datasets, methodologies, or infrastructure needs.\nProject Groups are topic-specific teams open to all i3 community members. They carry out the substantive research and data-development work of i3, including dataset construction, methodological documentation, and community education. Any community member may propose a new Project Group; formation requires approval by the Project Lead or the Steering Committee. Project Groups operate with significant autonomy but report periodically to the Steering Committee and the broader community on their activities and outputs.\n\n\n\n\n\n\ni3 membership is open to researchers, students, and practitioners actively engaged in innovation research. Members are expected to participate constructively in the community, which may include contributing to Project Groups, attending community meetings, and proposing new initiatives. There are no formal membership dues; i3 relies on the voluntary contributions of time and expertise from its members, as well as financial support from donations, grants, and institutional partners.\n\n\n\nNew members are nominated by existing Steering Committee members or the broader i3 community and confirmed by a majority vote of the Steering Committee. There are no formal term limits, though the Steering Committee encourages periodic renewal of membership to bring in new voices. Members wishing to step down should provide reasonable notice to allow for an orderly transition.\n\n\n\n\nThe Steering Committee is responsible for the financial health of i3. It approves annual budgets and any individual expenditure above $5,000. The Project Lead has authority to approve expenditures below this threshold in the ordinary course of operations. i3’s funding sources include donations from individual researchers and institutions, grants from foundations and government agencies, and other forms of institutional support.\nTo support long-term financial sustainability, i3 is exploring fiscal sponsorship through numFocus, a nonprofit that provides financial and administrative infrastructure for open-source scientific projects. Under this arrangement, individuals and institutions would be able to make tax-deductible donations to support i3’s infrastructure and dataset maintenance. An annual financial report will be made publicly available on the i3 website.\n\n\n\ni3 follows a tiered decision-making model designed to balance efficiency with accountability. Routine operational matters — including expenditures under $5,000, day-to-day project management, and community communications — are handled by the Project Lead. Major decisions, including budget approval, governance changes, new Steering Committee members, and significant strategic shifts, require a majority vote of the Steering Committee. The Steering Committee aims to hold regular meetings (at least twice per year) and to conduct business by email or video conference as needed between meetings.\n\n\n\n\n\ni3 is committed to fostering an inclusive, respectful, and collaborative community. All members must: - Treat others with respect and professionalism - Value diverse perspectives and contributions - Adhere to principles of open science and reproducibility - Properly attribute and cite others’ work - Protect confidential or sensitive information\n\n\n\nReports of Code of Conduct violations should be submitted to [designated contact]. The Steering Committee will investigate and determine appropriate actions, which may include warnings, temporary suspension, or removal from the community.\n\n\n\n\n\n\nAll datasets, code, and documentation produced by i3 or with i3 funds should be released under permissive open licenses: - Data: CC0 or CC-BY 4.0 - Code: MIT, Apache 2.0, or BSD - Documentation: CC-BY 4.0\n\n\n\nContributors retain credit for their work. i3 requires proper attribution and citation of datasets and tools.\n\n\n\nContributors who use i3 infrastructure or funding agree to license their outputs openly as specified above.\n\n\n\n\nThis governance document may be amended by: - Two-thirds vote of the Steering Committee - Community consultation period (minimum 30 days)\n\n\n\nIn the event of dissolution: - All remaining funds will be transferred another organization supporting open science - All datasets and tools will remain publicly available - Documentation will be archived in long-term repositories\n\n\n\nEffective Date: [Insert Date]\nReview Schedule: This governance document will be reviewed annually by the Steering Committee and updated as needed.\n\n\n\n\nSteering Committee: (need to add term expirations) - Adam Jaffe - Samuel Klein - Matt Marx - Bronwyn Hall - Bhaven Sampat - Agnes Cameron - Dror Shvadron\nProject Lead(s): - Matt Marx Contact Information: - Email: mmarx@cornell.edu"
  },
  {
    "objectID": "governance.html#mission-and-purpose",
    "href": "governance.html#mission-and-purpose",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "The Innovation Information Initiative (i3) is a global community of economists and innovation scholars dedicated to building open, interoperable datasets to advance research on science, technology, innovation, and entrepreneurship. i3 develops high-quality public datasets, shares methodological best practices, and coordinates research infrastructure to democratize access to innovation research data."
  },
  {
    "objectID": "governance.html#organizational-structure",
    "href": "governance.html#organizational-structure",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "The Steering Committee is the primary governing body of i3, responsible for setting strategic direction and making major organizational decisions. It comprises five to seven members serving staggered three-year terms, providing continuity while enabling the regular introduction of new perspectives. Decisions are made by simple majority vote of members present at a duly constituted meeting. The Steering Committee approves annual budgets, expenditures above $5,000, changes to governance policies, and the admission of new Steering Committee members.\nDecision-Making: - Decisions require a simple majority vote - Quorum: At least 50% of committee members must be present - Meetings held at least semiannually\n\n\n\nThe Project Lead manages day-to-day operations, maintains technical infrastructure, and serves as the primary point of contact for i3. The Project Lead is authorized to approve expenditures under $5,000 without prior Steering Committee approval and is responsible for preparing agendas for Steering Committee meetings, maintaining records of decisions, and reporting regularly to the Steering Committee on operational matters.\n\n\n\nTopic-specific project groups may be established by the Steering Committee or community members to focus on particular datasets, methodologies, or infrastructure needs.\nProject Groups are topic-specific teams open to all i3 community members. They carry out the substantive research and data-development work of i3, including dataset construction, methodological documentation, and community education. Any community member may propose a new Project Group; formation requires approval by the Project Lead or the Steering Committee. Project Groups operate with significant autonomy but report periodically to the Steering Committee and the broader community on their activities and outputs."
  },
  {
    "objectID": "governance.html#membership",
    "href": "governance.html#membership",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "i3 membership is open to researchers, students, and practitioners actively engaged in innovation research. Members are expected to participate constructively in the community, which may include contributing to Project Groups, attending community meetings, and proposing new initiatives. There are no formal membership dues; i3 relies on the voluntary contributions of time and expertise from its members, as well as financial support from donations, grants, and institutional partners.\n\n\n\nNew members are nominated by existing Steering Committee members or the broader i3 community and confirmed by a majority vote of the Steering Committee. There are no formal term limits, though the Steering Committee encourages periodic renewal of membership to bring in new voices. Members wishing to step down should provide reasonable notice to allow for an orderly transition."
  },
  {
    "objectID": "governance.html#financial-management",
    "href": "governance.html#financial-management",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "The Steering Committee is responsible for the financial health of i3. It approves annual budgets and any individual expenditure above $5,000. The Project Lead has authority to approve expenditures below this threshold in the ordinary course of operations. i3’s funding sources include donations from individual researchers and institutions, grants from foundations and government agencies, and other forms of institutional support.\nTo support long-term financial sustainability, i3 is exploring fiscal sponsorship through numFocus, a nonprofit that provides financial and administrative infrastructure for open-source scientific projects. Under this arrangement, individuals and institutions would be able to make tax-deductible donations to support i3’s infrastructure and dataset maintenance. An annual financial report will be made publicly available on the i3 website."
  },
  {
    "objectID": "governance.html#decision-making-processes",
    "href": "governance.html#decision-making-processes",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "i3 follows a tiered decision-making model designed to balance efficiency with accountability. Routine operational matters — including expenditures under $5,000, day-to-day project management, and community communications — are handled by the Project Lead. Major decisions, including budget approval, governance changes, new Steering Committee members, and significant strategic shifts, require a majority vote of the Steering Committee. The Steering Committee aims to hold regular meetings (at least twice per year) and to conduct business by email or video conference as needed between meetings."
  },
  {
    "objectID": "governance.html#code-of-conduct",
    "href": "governance.html#code-of-conduct",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "i3 is committed to fostering an inclusive, respectful, and collaborative community. All members must: - Treat others with respect and professionalism - Value diverse perspectives and contributions - Adhere to principles of open science and reproducibility - Properly attribute and cite others’ work - Protect confidential or sensitive information\n\n\n\nReports of Code of Conduct violations should be submitted to [designated contact]. The Steering Committee will investigate and determine appropriate actions, which may include warnings, temporary suspension, or removal from the community."
  },
  {
    "objectID": "governance.html#intellectual-property-and-licensing",
    "href": "governance.html#intellectual-property-and-licensing",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "All datasets, code, and documentation produced by i3 or with i3 funds should be released under permissive open licenses: - Data: CC0 or CC-BY 4.0 - Code: MIT, Apache 2.0, or BSD - Documentation: CC-BY 4.0\n\n\n\nContributors retain credit for their work. i3 requires proper attribution and citation of datasets and tools.\n\n\n\nContributors who use i3 infrastructure or funding agree to license their outputs openly as specified above."
  },
  {
    "objectID": "governance.html#amendments",
    "href": "governance.html#amendments",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "This governance document may be amended by: - Two-thirds vote of the Steering Committee - Community consultation period (minimum 30 days)"
  },
  {
    "objectID": "governance.html#dissolution",
    "href": "governance.html#dissolution",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "In the event of dissolution: - All remaining funds will be transferred another organization supporting open science - All datasets and tools will remain publicly available - Documentation will be archived in long-term repositories"
  },
  {
    "objectID": "governance.html#effective-date-and-review",
    "href": "governance.html#effective-date-and-review",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "Effective Date: [Insert Date]\nReview Schedule: This governance document will be reviewed annually by the Steering Committee and updated as needed."
  },
  {
    "objectID": "governance.html#appendix-a-current-leadership",
    "href": "governance.html#appendix-a-current-leadership",
    "title": "Innovation Information Initiative (i3) Governance Document",
    "section": "",
    "text": "Steering Committee: (need to add term expirations) - Adam Jaffe - Samuel Klein - Matt Marx - Bronwyn Hall - Bhaven Sampat - Agnes Cameron - Dror Shvadron\nProject Lead(s): - Matt Marx Contact Information: - Email: mmarx@cornell.edu"
  },
  {
    "objectID": "fellows.html",
    "href": "fellows.html",
    "title": "i3 Fellows",
    "section": "",
    "text": "University of Turin\n\n\nThis project develops an open dataset and transparent methodology to identify research institutes in bibliographic databases and classify them as public, private, or hybrid using LLMs and RAG on Wikipedia and official webpages.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNorthwestern\n\n\nGeorgi will build and continuously update a public dataset of corporate product launch announcements by scraping press releases (e.g., PRNewswire) and classifying them with a fine-tuned transformer model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nStanford\n\n\nUsing LLMs and clustering, this project will extract and categorize author-action sentences (e.g., “we propose an estimator”) from millions of paper abstracts to create the first large-scale dataset of fine-grained scientific tasks.\n\n\n\n\n\n\n\n\n\n\n\n\n\nVirginia Tech\n\n\nThe project will digitize and standardize all historical Indian patents from 1900–2005, link them to UK and US counterparts, and classify them using the CPC system.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIT\n\n\nRandol will integrate structured Traditional Chinese Medicine data (herbs, compounds, formulas from TCM Bank) with modern drug, patent, and clinical-trial databases, standardizing names and mapping ancient indications to MeSH/ICD codes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniversity of Georgia\n\n\nThe project will produce and maintain an open patent-ID–firm–month panel of in-force U.S. patents for Compustat firms, correctly accounting for subsidiary patents, assignments, and maintenance-fee events.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniversity of Toronto\n\n\nLLM_AuditKit is an open-source Python package that audits large language models for embedded producer-specific biases that trade off factual accuracy for perceived harmlessness.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUCLA\n\n\nYujing will create an open, reproducible dataset tracking Chinese scientists trained in the U.S. (1911–1953) and their return to China, linking historical student directories, biographical records, and modern bibliometric data (OpenAlex, CNKI).\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "fellows.html#current-fellows-2026",
    "href": "fellows.html#current-fellows-2026",
    "title": "i3 Fellows",
    "section": "",
    "text": "University of Turin\n\n\nThis project develops an open dataset and transparent methodology to identify research institutes in bibliographic databases and classify them as public, private, or hybrid using LLMs and RAG on Wikipedia and official webpages.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNorthwestern\n\n\nGeorgi will build and continuously update a public dataset of corporate product launch announcements by scraping press releases (e.g., PRNewswire) and classifying them with a fine-tuned transformer model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nStanford\n\n\nUsing LLMs and clustering, this project will extract and categorize author-action sentences (e.g., “we propose an estimator”) from millions of paper abstracts to create the first large-scale dataset of fine-grained scientific tasks.\n\n\n\n\n\n\n\n\n\n\n\n\n\nVirginia Tech\n\n\nThe project will digitize and standardize all historical Indian patents from 1900–2005, link them to UK and US counterparts, and classify them using the CPC system.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIT\n\n\nRandol will integrate structured Traditional Chinese Medicine data (herbs, compounds, formulas from TCM Bank) with modern drug, patent, and clinical-trial databases, standardizing names and mapping ancient indications to MeSH/ICD codes.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniversity of Georgia\n\n\nThe project will produce and maintain an open patent-ID–firm–month panel of in-force U.S. patents for Compustat firms, correctly accounting for subsidiary patents, assignments, and maintenance-fee events.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniversity of Toronto\n\n\nLLM_AuditKit is an open-source Python package that audits large language models for embedded producer-specific biases that trade off factual accuracy for perceived harmlessness.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUCLA\n\n\nYujing will create an open, reproducible dataset tracking Chinese scientists trained in the U.S. (1911–1953) and their return to China, linking historical student directories, biographical records, and modern bibliometric data (OpenAlex, CNKI).\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "fellows.html#alumni",
    "href": "fellows.html#alumni",
    "title": "i3 Fellows",
    "section": "Alumni",
    "text": "Alumni\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Name\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nName\n\n\n\nAffiliation\n\n\n\nResearch Topic\n\n\n\nCohort\n\n\n\n\n\n\n\n\nGuilherme Junqueira\n\n\nUniversity of Florida, Finance\n\n\nA new comprehensive dataset documenting financing sources for young innovative firms. \n\n\n2025\n\n\n\n\n\n\nKyoungah Noh\n\n\nUniversity at Albany SUNY, Economics\n\n\nA comprehensive dataset of standardized priority dates for patents. \n\n\n2025\n\n\n\n\n\n\nLaura Shupp\n\n\nMIT Sloan\n\n\nA comprehensive patent dataset covering the Middle East and North Africa. \n\n\n2025\n\n\n\n\n\n\nMatthew Lee Chen\n\n\nHarvard Economics\n\n\nCategorization of citations as “deep” or “shallow” for a broad corpus of 19th- and 20th-century British and American scientific articles and patents. \n\n\n2025\n\n\n\n\n\n\nMihai Codreanu\n\n\nStanford Economics\n\n\nA database of electronics products using 20th-century historical data, matched to patents via LLMs. \n\n\n2025\n\n\n\n\n\n\nRebekah Dix\n\n\nMIT Economics\n\n\nA dataset of combination innovations in medicine using LLMs and clinical trials data. \n\n\n2025\n\n\n\n\n\n\nTianshu Lyu\n\n\nYale School of Management\n\n\nA new matched dataset of consumer products with patents using detailed product-level data and topic modeling techniques. \n\n\n2025\n\n\n\n\n\n\nAlexander Kann\n\n\nUniversity of Mannheim\n\n\nAlexander developed a sophisticated classifier using BERT (Bidirectional Encoder Representations from Transformers) to identify and match defensive disclosures with their corresponding patent technology classifications. \n\n\n2024\n\n\n\n\n\n\nBernardo Dionisi\n\n\nDuke University\n\n\nBernardo created Pydrad, an open-source Python package designed to streamline the construction, transformation, combination, and comparison of innovation datasets. \n\n\n2024\n\n\n\n\n\n\nMatteo Tranchero\n\n\nUC Berkeley\n\n\nMatteo utilized Bio-BERT to develop a novel innovation impact metric based on “knowledge entities” rather than traditional citation counts. \n\n\n2024\n\n\n\n\n\n\nMaya Durvasula\n\n\nStanford University\n\n\nMaya applied large language models to integrate three critical data sources: clinical trial records from ClinicalTrials.gov, scientific publications, and FDA approval data. \n\n\n2024\n\n\n\n\n\n\nSaqib Mumtaz\n\n\nUC Berkeley\n\n\nSaqib’s research connects scientific publications with their media coverage by linking EurekaAlert press release data to OpenAlex author information. \n\n\n2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "2023 I3 Open Data Fellows\n\n\nFellows program announcement\n\n\nThe Innovation Information Initiative granted five fellowships to PhD students researching innovation in 2023. Fellows developed tools for defensive disclosures, open-source…\n\n\n\nOct 4, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Us",
    "section": "",
    "text": "All participants are welcome to join the Innovation Information Initiative. We have hosted regular convenings since 2019 to shape this collaborative and share our work."
  },
  {
    "objectID": "contact.html#get-involved",
    "href": "contact.html#get-involved",
    "title": "Contact Us",
    "section": "",
    "text": "All participants are welcome to join the Innovation Information Initiative. We have hosted regular convenings since 2019 to shape this collaborative and share our work."
  },
  {
    "objectID": "contact.html#contact-information",
    "href": "contact.html#contact-information",
    "title": "Contact Us",
    "section": "Contact Information",
    "text": "Contact Information\nFor questions, contributions, or to get involved with I³, please reach out:\n\nWebsite: https://iii.pubpub.org/"
  },
  {
    "objectID": "contact.html#contributing",
    "href": "contact.html#contributing",
    "title": "Contact Us",
    "section": "Contributing",
    "text": "Contributing\nWe welcome contributions in several areas:\n\nEssays and Notes: Share your research and insights related to innovation data\nDatasets: Contribute datasets or scripts to our public repository\nTechnical Working Group: Join our regular convenings and technical discussions\nFeedback: Help us improve the initiative by sharing your ideas"
  },
  {
    "objectID": "contact.html#support",
    "href": "contact.html#support",
    "title": "Contact Us",
    "section": "Support",
    "text": "Support\nThe Innovation Information Initiative is supported by the Alfred P. Sloan Foundation, with facilitation by NBER and the Knowledge Futures Group."
  },
  {
    "objectID": "contact.html#founding-members",
    "href": "contact.html#founding-members",
    "title": "Contact Us",
    "section": "Founding Members",
    "text": "Founding Members\n\nAdam Jaffe\nOsmat Jefferson\nSamuel Klein\nMatt Marx\nGaetan de Rassenfosse\nJames Weis\nBronwyn Hall\nBhaven Sampat"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We pledge to make our community welcoming, safe, and equitable for all.\nWe are committed to fostering an environment that respects and promotes the dignity, rights, and contributions of all individuals, regardless of characteristics including race, ethnicity, caste, color, age, physical characteristics, neurodiversity, disability, sex or gender, gender identity or expression, sexual orientation, language, philosophy or religion, national or social origin, socio-economic position, level of education, or other status. The same privileges of participation are extended to everyone who participates in good faith and in accordance with this Covenant.\n\n\n\nWhile acknowledging differences in social norms, we all strive to meet our community’s expectations for positive behavior. We also understand that our words and actions may be interpreted differently than we intend based on culture, background, or native language.\nWith these considerations in mind, we agree to behave mindfully toward each other and act in ways that center our shared values, including:\n\nRespecting the purpose of our community, our activities, and our ways of gathering.\nEngaging kindly and honestly with others.\nRespecting different viewpoints and experiences.\nTaking responsibility for our actions and contributions.\nGracefully giving and accepting constructive feedback.\nCommitting to repairing harm when it occurs.\nBehaving in other ways that promote and sustain the well-being of our community.\n\n\n\n\nWe agree to restrict the following behaviors in our community. Instances, threats, and promotion of these behaviors are violations of this Code of Conduct.\n\nHarassment. Violating explicitly expressed boundaries or engaging in unnecessary personal attention after any clear request to stop.\nCharacter attacks. Making insulting, demeaning, or pejorative comments directed at a community member or group of people.\nStereotyping or discrimination. Characterizing anyone’s personality or behavior on the basis of immutable identities or traits.\nSexualization. Behaving in a way that would generally be considered inappropriately intimate in the context or purpose of the community.\nViolating confidentiality. Sharing or acting on someone’s personal or private information without their permission.\nEndangerment. Causing, encouraging, or threatening violence or other harm toward any person or group.\nBehaving in other ways that threaten the well-being of our community.\n\n\n\n\nMisleading identity. Impersonating someone else for any reason, or pretending to be someone else to evade enforcement actions.\nFailing to credit sources. Not properly crediting the sources of content you contribute.\nPromotional materials. Sharing marketing or other commercial content in a way that is outside the norms of the community.\nIrresponsible communication. Failing to responsibly present content which includes, links or describes any other restricted behaviors.\n\n\n\n\n\nTensions can occur between community members even when they are trying their best to collaborate. Not every conflict represents a code of conduct violation, and this Code of Conduct reinforces encouraged behaviors and norms that can help avoid conflicts and minimize harm.\nWhen an incident does occur, it is important to report it promptly. To report a possible violation, please contact the community leaders through our contact page.\nCommunity Moderators take reports of violations seriously and will make every effort to respond in a timely manner. They will investigate all reports of code of conduct violations, reviewing messages, logs, and recordings, or interviewing witnesses and other participants. Community Moderators will keep investigation and enforcement actions as transparent as possible while prioritizing safety and confidentiality. In order to honor these values, enforcement actions are carried out in private with the involved parties, but communicating to the whole community may be part of a mutually agreed upon resolution.\n\n\n\nIf an investigation by the Community Moderators finds that this Code of Conduct has been violated, the following enforcement ladder may be used to determine how best to repair harm, based on the incident’s impact on the individuals involved and the community as a whole. Depending on the severity of a violation, lower rungs on the ladder may be skipped.\n\nWarning\n\nEvent: A violation involving a single incident or series of incidents.\nConsequence: A private, written warning from the Community Moderators.\nRepair: Examples of repair include a private written apology, acknowledgement of responsibility, and seeking clarification on expectations.\n\nTemporarily Limited Activities\n\nEvent: A repeated incidence of a violation that previously resulted in a warning, or the first incidence of a more serious violation.\nConsequence: A private, written warning with a time-limited cooldown period designed to underscore the seriousness of the situation and give the community members involved time to process the incident. The cooldown period may be limited to particular communication channels or interactions with particular community members.\nRepair: Examples of repair may include making an apology, using the cooldown period to reflect on actions and impact, and being thoughtful about re-entering community spaces after the period is over.\n\nTemporary Suspension\n\nEvent: A pattern of repeated violation which the Community Moderators have tried to address with warnings, or a single serious violation.\nConsequence: A private written warning with conditions for return from suspension. In general, temporary suspensions give the person being suspended time to reflect upon their behavior and possible corrective actions.\nRepair: Examples of repair include respecting the spirit of the suspension, meeting the specified conditions for return, and being thoughtful about how to reintegrate with the community when the suspension is lifted.\n\nPermanent Ban\n\nEvent: A pattern of repeated code of conduct violations that other steps on the ladder have failed to resolve, or a violation so serious that the Community Moderators determine there is no way to keep the community safe with this person as a member.\nConsequence: Access to all community spaces, tools, and communication channels is removed. In general, permanent bans should be rarely used, should have strong reasoning behind them, and should only be resorted to if working through other remedies has failed to change the behavior.\nRepair: There is no possible repair in cases of this severity.\n\n\nThis enforcement ladder is intended as a guideline. It does not limit the ability of Community Managers to use their discretion and judgment, in keeping with the best interests of our community.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public or other spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 3.0, permanently available at https://www.contributor-covenant.org/version/3/0/.\nContributor Covenant is stewarded by the Organization for Ethical Source and licensed under CC BY-SA 4.0. To view a copy of this license, visit https://creativecommons.org/licenses/by-sa/4.0/\nFor answers to common questions about Contributor Covenant, see the FAQ at https://www.contributor-covenant.org/faq. Translations are provided at https://www.contributor-covenant.org/translations. Additional enforcement and community guideline resources can be found at https://www.contributor-covenant.org/resources. The enforcement ladder was inspired by the work of Mozilla’s code of conduct team."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Code of Conduct",
    "section": "",
    "text": "We pledge to make our community welcoming, safe, and equitable for all.\nWe are committed to fostering an environment that respects and promotes the dignity, rights, and contributions of all individuals, regardless of characteristics including race, ethnicity, caste, color, age, physical characteristics, neurodiversity, disability, sex or gender, gender identity or expression, sexual orientation, language, philosophy or religion, national or social origin, socio-economic position, level of education, or other status. The same privileges of participation are extended to everyone who participates in good faith and in accordance with this Covenant."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#encouraged-behaviors",
    "href": "CODE_OF_CONDUCT.html#encouraged-behaviors",
    "title": "Code of Conduct",
    "section": "",
    "text": "While acknowledging differences in social norms, we all strive to meet our community’s expectations for positive behavior. We also understand that our words and actions may be interpreted differently than we intend based on culture, background, or native language.\nWith these considerations in mind, we agree to behave mindfully toward each other and act in ways that center our shared values, including:\n\nRespecting the purpose of our community, our activities, and our ways of gathering.\nEngaging kindly and honestly with others.\nRespecting different viewpoints and experiences.\nTaking responsibility for our actions and contributions.\nGracefully giving and accepting constructive feedback.\nCommitting to repairing harm when it occurs.\nBehaving in other ways that promote and sustain the well-being of our community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#restricted-behaviors",
    "href": "CODE_OF_CONDUCT.html#restricted-behaviors",
    "title": "Code of Conduct",
    "section": "",
    "text": "We agree to restrict the following behaviors in our community. Instances, threats, and promotion of these behaviors are violations of this Code of Conduct.\n\nHarassment. Violating explicitly expressed boundaries or engaging in unnecessary personal attention after any clear request to stop.\nCharacter attacks. Making insulting, demeaning, or pejorative comments directed at a community member or group of people.\nStereotyping or discrimination. Characterizing anyone’s personality or behavior on the basis of immutable identities or traits.\nSexualization. Behaving in a way that would generally be considered inappropriately intimate in the context or purpose of the community.\nViolating confidentiality. Sharing or acting on someone’s personal or private information without their permission.\nEndangerment. Causing, encouraging, or threatening violence or other harm toward any person or group.\nBehaving in other ways that threaten the well-being of our community.\n\n\n\n\nMisleading identity. Impersonating someone else for any reason, or pretending to be someone else to evade enforcement actions.\nFailing to credit sources. Not properly crediting the sources of content you contribute.\nPromotional materials. Sharing marketing or other commercial content in a way that is outside the norms of the community.\nIrresponsible communication. Failing to responsibly present content which includes, links or describes any other restricted behaviors."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#reporting-an-issue",
    "href": "CODE_OF_CONDUCT.html#reporting-an-issue",
    "title": "Code of Conduct",
    "section": "",
    "text": "Tensions can occur between community members even when they are trying their best to collaborate. Not every conflict represents a code of conduct violation, and this Code of Conduct reinforces encouraged behaviors and norms that can help avoid conflicts and minimize harm.\nWhen an incident does occur, it is important to report it promptly. To report a possible violation, please contact the community leaders through our contact page.\nCommunity Moderators take reports of violations seriously and will make every effort to respond in a timely manner. They will investigate all reports of code of conduct violations, reviewing messages, logs, and recordings, or interviewing witnesses and other participants. Community Moderators will keep investigation and enforcement actions as transparent as possible while prioritizing safety and confidentiality. In order to honor these values, enforcement actions are carried out in private with the involved parties, but communicating to the whole community may be part of a mutually agreed upon resolution."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#addressing-and-repairing-harm",
    "href": "CODE_OF_CONDUCT.html#addressing-and-repairing-harm",
    "title": "Code of Conduct",
    "section": "",
    "text": "If an investigation by the Community Moderators finds that this Code of Conduct has been violated, the following enforcement ladder may be used to determine how best to repair harm, based on the incident’s impact on the individuals involved and the community as a whole. Depending on the severity of a violation, lower rungs on the ladder may be skipped.\n\nWarning\n\nEvent: A violation involving a single incident or series of incidents.\nConsequence: A private, written warning from the Community Moderators.\nRepair: Examples of repair include a private written apology, acknowledgement of responsibility, and seeking clarification on expectations.\n\nTemporarily Limited Activities\n\nEvent: A repeated incidence of a violation that previously resulted in a warning, or the first incidence of a more serious violation.\nConsequence: A private, written warning with a time-limited cooldown period designed to underscore the seriousness of the situation and give the community members involved time to process the incident. The cooldown period may be limited to particular communication channels or interactions with particular community members.\nRepair: Examples of repair may include making an apology, using the cooldown period to reflect on actions and impact, and being thoughtful about re-entering community spaces after the period is over.\n\nTemporary Suspension\n\nEvent: A pattern of repeated violation which the Community Moderators have tried to address with warnings, or a single serious violation.\nConsequence: A private written warning with conditions for return from suspension. In general, temporary suspensions give the person being suspended time to reflect upon their behavior and possible corrective actions.\nRepair: Examples of repair include respecting the spirit of the suspension, meeting the specified conditions for return, and being thoughtful about how to reintegrate with the community when the suspension is lifted.\n\nPermanent Ban\n\nEvent: A pattern of repeated code of conduct violations that other steps on the ladder have failed to resolve, or a violation so serious that the Community Moderators determine there is no way to keep the community safe with this person as a member.\nConsequence: Access to all community spaces, tools, and communication channels is removed. In general, permanent bans should be rarely used, should have strong reasoning behind them, and should only be resorted to if working through other remedies has failed to change the behavior.\nRepair: There is no possible repair in cases of this severity.\n\n\nThis enforcement ladder is intended as a guideline. It does not limit the ability of Community Managers to use their discretion and judgment, in keeping with the best interests of our community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public or other spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 3.0, permanently available at https://www.contributor-covenant.org/version/3/0/.\nContributor Covenant is stewarded by the Organization for Ethical Source and licensed under CC BY-SA 4.0. To view a copy of this license, visit https://creativecommons.org/licenses/by-sa/4.0/\nFor answers to common questions about Contributor Covenant, see the FAQ at https://www.contributor-covenant.org/faq. Translations are provided at https://www.contributor-covenant.org/translations. Additional enforcement and community guideline resources can be found at https://www.contributor-covenant.org/resources. The enforcement ladder was inspired by the work of Mozilla’s code of conduct team."
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Public Datasets and Scripts",
    "section": "",
    "text": "The Innovation Information Initiative provides access to public datasets and scripts for innovation research."
  },
  {
    "objectID": "datasets.html#available-datasets",
    "href": "datasets.html#available-datasets",
    "title": "Public Datasets and Scripts",
    "section": "Available Datasets",
    "text": "Available Datasets\n\nPatent Datasets\n\nPatent citation graphs\nPatent-scholarship citation links\nPatent metadata\n\n\n\nRelated Datasets\n\nPatent-product links\nScholarship-funding data\nAuthor and affiliation disambiguation datasets"
  },
  {
    "objectID": "datasets.html#scripts-and-tools",
    "href": "datasets.html#scripts-and-tools",
    "title": "Public Datasets and Scripts",
    "section": "Scripts and Tools",
    "text": "Scripts and Tools\nComing soon."
  },
  {
    "objectID": "datasets.html#contributing-datasets",
    "href": "datasets.html#contributing-datasets",
    "title": "Public Datasets and Scripts",
    "section": "Contributing Datasets",
    "text": "Contributing Datasets\nIf you have datasets or scripts you’d like to contribute to I³, please contact us."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Journal\n      \n      \n        Year - Oldest\n      \n      \n        Year - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "events/2021-technical-working-group/index.html",
    "href": "events/2021-technical-working-group/index.html",
    "title": "2021 Technical Working Group Meeting",
    "section": "",
    "text": "December 3-4, 2021 | Cambridge, MA (NBER) | Agenda"
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#friday-december-3",
    "href": "events/2021-technical-working-group/index.html#friday-december-3",
    "title": "2021 Technical Working Group Meeting",
    "section": "Friday, December 3",
    "text": "Friday, December 3\n\nWelcome and Introductions!\nAdam Jaffe, Brandeis University and NBER\n\n\n\nText Analysis"
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#the-rise-of-process-claims-evidence-from-a-century-of-u.s.-patents-slides",
    "href": "events/2021-technical-working-group/index.html#the-rise-of-process-claims-evidence-from-a-century-of-u.s.-patents-slides",
    "title": "2021 Technical Working Group Meeting",
    "section": "The Rise of Process Claims: Evidence from a Century of U.S. Patents (slides)",
    "text": "The Rise of Process Claims: Evidence from a Century of U.S. Patents (slides)\nBernhard Ganglmair, ZEW Mannheim\nW. Keith Robinson, Wake Forest University Michael Seeligson, Southern Methodist University\nAn approach to classifying claims, beyond keyword searches. We will be sharing code & data (on Github & Zenodo) for others to use and adapt.\nDiscussion:\nQ: When you’re relying on textual models, what problems come up w/ formulas and schematics, given how they are represented in those patents?\nA: (Bruno + Bernhard looked at each other and both rolled their eyes, indicating this is a hard problem! ) Bruno: This is not something we are picking up, and these are important elements. Even if you think about Josh Greer’s work in pharma… molecules, and how they are picked up… if it’s not expressed in words, we will miss it for now. That’s a challenge, more in some areas than in others. A: Bernhard: Looking at our coverage, how well we do for claims in chem and biology, we’re missing a lot. I’ve just recently come across a dataset of a few hundred thousand manually classified claims in chemicals. If you are in the audience, please call me — I would love to use the dataset just to see how well we do w/ a large sample of chemicals, to improve on the approach."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#modeling-patent-clarity",
    "href": "events/2021-technical-working-group/index.html#modeling-patent-clarity",
    "title": "2021 Technical Working Group Meeting",
    "section": "Modeling Patent Clarity",
    "text": "Modeling Patent Clarity\nJonathan Ashtor, Cardozo School of Law\nCan the definiteness requirement be used to model claim clarity, at issuance and publication? This work modeled linguistic features of claims, and trained an ML model on rejections using these features.\nDiscussion:\nQ: Do we know anything about which firms write better patents?\nA: Portfolio size may bear on this; I don’t look at the division or subsidiary level, just at the general size of the portfolio, so it’s a bit rough."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#technology-differentiation-and-firm-performance",
    "href": "events/2021-technical-working-group/index.html#technology-differentiation-and-firm-performance",
    "title": "2021 Technical Working Group Meeting",
    "section": "Technology Differentiation and Firm Performance",
    "text": "Technology Differentiation and Firm Performance\nBruno Cassiman, IESE\nSam Arts, KU Leuven\nJianan Hou, KU Leuven\nHow do we characterize the tech portfolio of a firm, and how does that correlate with firm performance? How can we use text to characterize the portfolio?\nThere is some work on measuring similarity and complementarity of the tech of different firms, but little theory + formal models. For a given year, we can plot firms in technology space.\nMeasures: portfolio similarity, technology differentiation (very different from patent similarity and citations)\nWe are sharing this method and open data, which could be used to look at other questions — characterizing portfolios by region, or by inventor.\nDiscussion:\nQ: How do you cluster / classify firms that work in many classes? (E.g.: firms compete at business unit level, not at corporate level.)\nA: We don’t cluster, trying to get away from classification…\nComment: Can we draw connections w/ Bernhard’s paper around differentiation and competitive advantage? Process vs product inventions are on a continuum, but if you think about process patents as cost-reducing and product patents as value creating, that might help distinguish different ways that firms try to differentiate.\nClosing comment: We had 2 papers that take the words in the patents at face value: “what does this tell us about the firm’s inventions?” and 1 paper that asks “how do firms write the patents they write?” This area is exciting – as someone who started w/ classifications, this clearly tells us much more. About both the invention and the applicant’s strategy."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#what-comes-after-microsoft-academic-graph",
    "href": "events/2021-technical-working-group/index.html#what-comes-after-microsoft-academic-graph",
    "title": "2021 Technical Working Group Meeting",
    "section": "What comes after Microsoft Academic Graph?",
    "text": "What comes after Microsoft Academic Graph?\n\nIntroducing OpenAlex - maintaining an open replacement for MAG (outline)\nJason Priem, OurResearch\nHeather Piwowar, OurResearch\nOpenAlex will provide a replacement for MAG, as of Jan. 3. The code and data will all be open. Here we describe 4 types of data you might be looking for: what was in MAG but is going away (patents!); what is frozen w/ no updates; what has ongoing support; what is new.\nFeedback welcome once this is out in January, please share how you are using it and what else you would like to see.\nDiscussion:\nMatt: Thank you! In some ways MAG going away was a good thing, as we have no documentation of what MAG did; no code, no benchmarks. Thanks for open sourcing everything: a quantum leap. We want to help; I may have data to share with you after Jan 3.\nQ: What are your thoughts on licensing the data? ODC-BY, other?\nA: Our current license is ‘none’ as with Crossref data. (CC0; facts are not copyrightable). Lawyers are arguing about this, we will keep our ears open if people think this is not true for some subset; but we don’t think we have the right to apply a [new] license to it."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#saturday-december-4",
    "href": "events/2021-technical-working-group/index.html#saturday-december-4",
    "title": "2021 Technical Working Group Meeting",
    "section": "Saturday, December 4",
    "text": "Saturday, December 4\n\nPrototyping an Innovation Data Portal (slides)\nIntroducing iiindex.org\nAgnes Cameron, Knowledge Futures Group\nA searchable update to the original I3 datasets index. Linked open data for each dataset, with annotations: metadata, examples, superceding data.\nYou can edit metadata in the original Google sheet, and can add longer-form markdown notes that display as usage guides alongside each entry.\nWe built this largely to include datasets and metadata that often don’t get captured on other platforms — links of inheritance, dependence, and supercession; related datasets; and timelines.\nYou can now add curated collections: a way to index thematic lists for a specific purpose. Items in a collection are often in the index as individual entries, but collections may include both larger and more granular elements.\nFeedback is warmly welcome! If you have ideas about how to approach dataset-relatedness, or other facets you would like to see, please share — as issues on the github repo or by email.\n\n\n\nFirms"
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#measuring-firms-technology-use-with-employees-job-data",
    "href": "events/2021-technical-working-group/index.html#measuring-firms-technology-use-with-employees-job-data",
    "title": "2021 Technical Working Group Meeting",
    "section": "Measuring Firms’ Technology Use with Employees’ Job Data",
    "text": "Measuring Firms’ Technology Use with Employees’ Job Data\nTania Babina, Columbia University\nAnastassia Fedyk, University of California at Berkeley\nAlex Xi He, University of Maryland\nJames Hodson, Jozef Stefan International Postgraduate School\nUsing employment and employee data from Burning Glass + Cognism. Before we had papers; now we have resumes: for firm-worker match data. We use this to infer AI skills in particular.\nDiscussion:\nQ: Do you cluster resumes to find duplicates for the same person?\nA: In 2018 there were 165M workers, we have resumes for 100M.\nQ: Is open data available?\nCognism: Firm-level measures + geographies will be released. Burning Glass: May be able to post aggregated data, need to ask | TBD.\nQ: Have you thought about generalizing this method to firms that use tech from elsewhere to do their work?\nComment: Really cool data! I thought an interesting result was that you find a positive correlation between the AI measure and the Hoberg-Phillips fluidity measure. What’s your interpretation of this? I guess you could imagine that firms are trying to maintain a competitive advantage, or are responding to a changing competitive landscape."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#matching-patent-assignees-to-startups",
    "href": "events/2021-technical-working-group/index.html#matching-patent-assignees-to-startups",
    "title": "2021 Technical Working Group Meeting",
    "section": "Matching Patent Assignees to Startups",
    "text": "Matching Patent Assignees to Startups\nMatt Marx, Cornell University and NBER\nMichael Ewens, California Institute of Technology and NBER\nNB: Small != Startup. Some orgs stay small. Youth != Startup. Some established orgs spin out branches that are ‘old’. We don’t want to reinvent the wheel, there are other efforts to match assignees to startups.\nHarmonizing a few sources: - OpenCorporates data: They are transparent about provenance, access is free; but no data on: headcounts, sales, industry ratings, industry field codes. - Form D filings: Doesn’t get all startups, but has a lot of them.\nDiscussion:\nComment: If you have inventor names, and employment, and know that an inventor took out a patent that led to a product at that company, that could be a useful sign.\n\n\nCompetition"
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#intellectual-property-theft-slides",
    "href": "events/2021-technical-working-group/index.html#intellectual-property-theft-slides",
    "title": "2021 Technical Working Group Meeting",
    "section": "Intellectual Property Theft (slides)",
    "text": "Intellectual Property Theft (slides)\nBritta Glennon, University of Pennsylvania and NBER\nDaniel P. Gross, Duke University and NBER\nLia Sheer, Tel-Aviv University\nIPR analysis: How do firms respond to (theft cases, theft trends)? How does theft affect their H1B hires, including specifically from China? How does it affect the # of immigrants they hire?\nAfter completing the work and putting out a first pub, will start sharing data privately with other researchers.\nThis is the hardest paper we’ve worked on yet, for reasons Britta notes.\nDiscussion:\nComment: MSU group in this area: https://a-capp.msu.edu/\nQ: Curious about how many of the people involved in the thefts were permanent residents. And how many first came to the US on a student visa. Are firms hiring different types of immigrants rather than fewer immigrants?\nA: That is a great point. Once we collect the additional data we hope to have a better understanding on the background of these workers.\nQ: Are cases initiated by firms or by DOJ? (Or is this known?) I’m trying to understand what share of theft might be captured by cases, and it seems like some firms may have incentives not to make it public they were successfully victimized.\nQ: Can we learn anything from the strategies of the thieves themselves? Are they stealing frontier tech?\nQ: This is really cool! Two thoughts… 1. How do you guys know what ‘event’ to code for the diff-in-diff: there’s the news catching the theft, the indictment of the spies, the verdict.. etc… and 2. Would be interesting to separate the cases where the defendant is ultimately found innocent vs guilty.\nA: These are great questions. We ideally want to be able to measure when the firm itself learned of the theft. At the moment we’re working with the earliest date we can get our hands on, which isn’t always that far back, but we have an RA trying to push deeper into the timelines as we speak.\nQ: What is the underlying theory behind the matched sample analysis? If a firm has not been affected should one think of this as a persistently lucky firm (which does not need to take any action to be safe) or should we think of it as a firm that has taken appropriate actions? In other words, I am not sure what story would generate a difference between the treated and control firms.\nA: We started looking also into spillovers to rival firms, but first want to understand the treated firm’s action. Indeed a lot to think about!\nComment: Can H1B be considered immigrants as this is a kind of non-immigrant visa? Comment: In the sense that people are moving to the US (for their jobs), they are immigrants, even if it’s not clear how long they will stay."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#u.s.-entrepreneurship-over-the-long-run-new-data-and-approaches-to-measurement-slides",
    "href": "events/2021-technical-working-group/index.html#u.s.-entrepreneurship-over-the-long-run-new-data-and-approaches-to-measurement-slides",
    "title": "2021 Technical Working Group Meeting",
    "section": "U.S. Entrepreneurship over the Long-run: New Data and Approaches to Measurement (slides)",
    "text": "U.S. Entrepreneurship over the Long-run: New Data and Approaches to Measurement (slides)\nDaniel P. Gross, Duke University and NBER\nJorge Guzman, Columbia University\nInnessa Colaiacovo, Harvard Business School\nDiscussion:\nQ: Is the real outlier the inter-war years?\nA: In the usual log-log GDP graphs, there is an outlier in the interwar and then a return to trend. In our case, we find a change in trend after the war. We have some hypothesis about what this means, still prelim so I’ll hold off :)\nQ: To what extent can you look beyond firm names? Can you look at firm descriptions ultimately?\nA: We’d love to, but can’t too much. One option could be to try to look at what the ‘filings’ say but they are mostly not digitized and are handwritten (in cursive!) when digitized for the earlier years in our sample… Q2: I wonder if you can capture related meanings beyond the words? For example, firm names might include “code” related to “program”?\nQ: With D&B data do you have a sense of establishment longevity? Or places going from single establishment to multi establishment firms?\nA: We have thought about this quite a bit, but matching the two and thinking about selection differences can be tricky… happy to hear your thoughts.\nComment: Thanks very much for another heroic data project! The change of ownerships would be interesting to trace too."
  },
  {
    "objectID": "events/2021-technical-working-group/index.html#patent-paper-pairs",
    "href": "events/2021-technical-working-group/index.html#patent-paper-pairs",
    "title": "2021 Technical Working Group Meeting",
    "section": "Patent-Paper Pairs",
    "text": "Patent-Paper Pairs\nMatt Marx, Cornell University and NBER\nFrame: 21 datasets used by 27 articles on patent-paper pairs. Most by hand, only one is open (PubMed, 15 pairs). Fiona, et al match to Web of Science; most don’t have full access to allow clean reuse. This is where we were w/ patent-paper cites 3+ years ago.\n\nHow do we define a PPP? Settle on a definition.\nAim to produce a broad public dataset. Link to OpenAlex, cover all fields (not just med), include advanced data: geography, affiliation.\n\nDiscussion:\nComment: It could be illegal to put CEO on patent when they were not involved –&gt; patent is worthless if challenged. But there are probably grey areas in both cases - defining what is a substantive/large enough contribution is often a debate. See https://www.science.org/doi/10.1126/sciadv.1700404\nQ: How do you decide what to work on?\nA: When you see lots of papers and no sharing of source datasets - the 21 sources for 27 papers - that’s an indication that there’s a role for a public good.\nQ: For temporal specificity - you can publish a paper up to 1 year after, measured from absolute priority date.\nQ: For pairs w/ no overlap of author+inventor: is that still a pair?\nA: Don’t only look at similarity; do you also require some similarity of content?\nAndy T: Authors and inventors should overlap by at least one person. If another person published something that is then in a patent app, it becomes prior art and should block the patent from grant. The author would have 1 year to submit before they undermine themselves for getting a patent.\nEmilio R: We are currently working on a project that exploits the funding source to identify the patent-paper pairs. It’s going to be limited in size but maybe not terrible.\nBhaven: (noting a gold-standard set you can measure against)\nQ: Can you separate different families?\nComment: Can you look at both cosine similarity, not just topic pairs? Matt: I hear people asking for more info about different fields, not just one ranking of “likelihood of being a PPP”.\n\nThanks for joining! For further questions or conversation, please join the I3 discussion list (i3-open).\n\nOriginal content published on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)"
  },
  {
    "objectID": "events/2019-technical-working-group/index.html",
    "href": "events/2019-technical-working-group/index.html",
    "title": "2019 Technical Working Group Meeting",
    "section": "",
    "text": "December 6-7, 2019 | Cambridge, MA"
  },
  {
    "objectID": "events/2019-technical-working-group/index.html#introduction",
    "href": "events/2019-technical-working-group/index.html#introduction",
    "title": "2019 Technical Working Group Meeting",
    "section": "Introduction",
    "text": "Introduction\nAdam B. Jaffe, MIT: Introduction to I³\n\nInitial data construction projects\nSamuel J. Klein, MIT: Prior Art + Open Innovation Metrics\nOsmat Azzam Jefferson, QUT and Lens.org: A Public Innovation Dataverse\nMatt Marx, BU: Toward a Complete Set of Patent References to Science\nGaétan de Rassenfosse, EPFL: Linking Products to Patents"
  },
  {
    "objectID": "events/2019-technical-working-group/index.html#panel-discussions",
    "href": "events/2019-technical-working-group/index.html#panel-discussions",
    "title": "2019 Technical Working Group Meeting",
    "section": "Panel discussions",
    "text": "Panel discussions\n\nDisambiguation\nChair: Bronwyn H. Hall, UC Berkeley + NBER\nLia Sheer, Duke University: The Role of Company Names and Ownership Changes in the Dynamic Reassignments of Patents\nDeyun Yin, WIPO:\nChallenges and Solutions in the Construction of Chinese Patent Database (paper)\nLisa D. Cook, Michigan State and NBER:\nRace, Ethnicity, and Patenting: USPTO’s New Data Collection Effort\n\n\n\nText Analysis\nChair: Samuel J. Klein\nMartina Iori, Sant’Anna School of Advanced Studies: The Complexity of Knowledge\nMitsuru Igami, Yale University: Mapping Firms’ Locations in Technological Space (paper)\nJeffrey M. Kuhn, UNC: Applications of Textual Similarity to Measure Construction and Evaluation\nDominique Guellec, Observatoire des Sciences et Techniques: Novelty and Impact\n\n\n\nOther Patent Data Endeavors & Complementarity with I³\nChair: Osmat Azzam Jefferson\nGaétan de Rassenfosse: PatStat overview Andrew Toole, USPTO Ian Wetherbee, Google: On BigQuery\n\n\n\nWrap-up: Goals, Mission and Priorities for I³\nChair: Adam B. Jaffe\nBronwyn H. Hall, UC Berkeley + NBER\nElisabeth Ruth Perlman, Bureau of the Census\nBhaven N. Sampat, Columbia + NBER\nHeidi L. Williams, Stanford + NBER\n\nOriginal content published on PubPub under Creative Commons Attribution 4.0 International License (CC-BY 4.0)"
  },
  {
    "objectID": "events/2025-technical-working-group/index.html",
    "href": "events/2025-technical-working-group/index.html",
    "title": "2025 Technical Working Group meeting",
    "section": "",
    "text": "December 5-6, 2025\nTBD"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the Initiative",
    "section": "",
    "text": "The Innovation Information Initiative (i3) is a data collaborative for open innovation data and related analytics, tools, & metrics. This includes patent datasets, citation graphs among + between patents and scholarship, and metrics or secondary datasets derived from these.\nWe are supported by the Alfred P. Sloan Foundation, with facilitation by NBER.\n\n\n\nAdam Jaffe\nSamuel Klein\nMatt Marx\nBronwyn Hall\nBhaven Sampat\nAgnes Cameron\nDror Shvadron\n\n\n\n\nWe are committed to providing a welcoming and inclusive environment for all participants. Please review our Code of Conduct to understand our community standards and expectations."
  },
  {
    "objectID": "about.html#steering-committee",
    "href": "about.html#steering-committee",
    "title": "About the Initiative",
    "section": "",
    "text": "Adam Jaffe\nSamuel Klein\nMatt Marx\nBronwyn Hall\nBhaven Sampat\nAgnes Cameron\nDror Shvadron"
  },
  {
    "objectID": "about.html#code-of-conduct",
    "href": "about.html#code-of-conduct",
    "title": "About the Initiative",
    "section": "",
    "text": "We are committed to providing a welcoming and inclusive environment for all participants. Please review our Code of Conduct to understand our community standards and expectations."
  },
  {
    "objectID": "CLAUDE.html",
    "href": "CLAUDE.html",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n\nThis is the Innovation Information Initiative (I³) website, built with Quarto and migrated from PubPub. It’s a static website for a data collaborative focused on open innovation data, patent datasets, citation graphs, and related analytics tools.\n\n\n\n\n\nquarto preview\nThis starts a local development server with live reload. The site will be available at http://localhost:XXXX (port will be shown in output).\n\n\n\nquarto render\nThis generates static files in the _site/ directory, which is the output directory for deployment.\n\n\n\nquarto --version\n\n\n\n\n\n\nThe site uses automatic content discovery with folder-based organization:\n\nEvents and News use folder structures with individual index.qmd files\nQuarto listing feature automatically discovers and displays content\nFeatured filtering controls which items appear on the homepage using featured: true in YAML front matter\nPublications still use publications.yml for centralized management\n\nAll template content from Deep Policy Lab has been removed - the site is clean and ready for I³ content migration.\n\n\n\n\n_quarto.yml: Main site configuration including navbar, theme, search, and global settings\nindex.qmd: Homepage with custom layout using Quarto listing blocks for news/events/publications\nreferences.bib: Bibliography file for academic citations\n\n\n\n\nNews: Folder-based structure with automatic discovery - Location: news/item-name/index.qmd - Required front matter: title, subtitle, description, author, date, image, categories - Images stored in: news/item-name/images/ - Set featured: true to display on homepage - All news items automatically appear on news.qmd\nEvents: Folder-based structure with automatic discovery - Location: events/event-name/index.qmd - Required front matter: title, subtitle, description, author, date, image, categories - Images stored in: events/event-name/images/ - Set featured: true to display on homepage - All events automatically appear on events.qmd\nPublications: Add entries to publications.yml - Fields: path, image, title, subtitle, description, date, fulltext, categories - Displayed on publications.qmd and homepage - Can filter by categories (e.g., “featured”)\nEssays: Create individual .qmd files - Page: essays.qmd\nDatasets: Edit datasets.qmd directly with dataset information\n\n\n\nThe site uses Quarto’s listing feature with automatic discovery and filtering:\nHomepage (index.qmd): - #news-events listing: Auto-discovers from events/*/index.qmd and news/*/index.qmd - Uses include: featured: true to filter homepage items - Shows only content marked as featured: true in front matter - #publications listing: Pulls from publications.yml\nIndividual listing pages: - events.qmd: Auto-discovers all events from events/*/index.qmd - news.qmd: Auto-discovers all news from news/*/index.qmd\nListing features: - Automatic content discovery using glob patterns - Sorting (e.g., “date desc”) - Multiple content sources - Grid/table layouts - Filtering by YAML front matter fields using include/exclude - Custom field display\n\n\n\n\nstyles.css: Main site stylesheet\ncustom.css: Additional custom styles (used on homepage)\ncenter.css: Specific layout styles\nTheme set to “cosmo” in _quarto.yml\nNavbar colors: background #05336B, foreground #FFFFFF\n\n\n\n\n\nevents/*/images/: Event-specific images (stored with each event)\nnews/*/images/: News-specific images (stored with each news item)\n/files/images/: Legacy image storage for publications, people, shared assets\n/files/includes/: Reusable content snippets (analytics, social sharing)\n\n_msclarity.qmd: Microsoft Clarity analytics\n_mswebmaster.js: Webmaster verification\n_academic.qmd, _socialshare.qmd: Template includes\n\n\n\n\n\n\nStandard pages: Use page-layout: full (About, News, Events, Publications, etc.)\nHomepage: Uses page-layout: custom with Quarto’s grid system\n\nGrid classes: .g-col-12, .g-col-md-7, etc.\nBackground frames: .background-frame, .alt-background\nContent blocks: .content-block\n\n\n\n\n\nThe site has a clean navigation structure in _quarto.yml: - About - I3 Essays - News - Events - Publications - Public Datasets - Contact\nAll placeholder/template pages have been removed.\n\n\n\n\n\n\nAdd a news item: 1. Create folder: news/news-item-name/ 2. Create news/news-item-name/index.qmd with front matter: yaml    ---    title: \"News Item Title\"    subtitle: \"Brief subtitle\"    description: \"Longer description for listings\"    author: \"Author Name\"    date: \"YYYY-MM-DD\"    image: images/image-name.png    categories: [category1, category2]    featured: true  # Set to true to show on homepage    --- 3. Add images to news/news-item-name/images/ 4. Write content below front matter 5. Preview with quarto preview\nAdd an event: 1. Create folder: events/event-name/ 2. Create events/event-name/index.qmd with front matter: yaml    ---    title: \"Event Title\"    subtitle: \"Event subtitle\"    description: \"Event description for listings\"    author:      - Author One      - Author Two    date: \"YYYY-MM-DD\"    image: images/image-name.png    categories: [workshop, category2]    featured: true  # Set to true to show on homepage    --- 3. Add images to events/event-name/images/ 4. Write event details below front matter 5. Preview changes\nAdd a publication: 1. Open publications.yml 2. Add entry with path, image, title, subtitle, description, date, fulltext, categories 3. Use categories for filtering (e.g., “featured”) 4. Preview changes\nControlling homepage display: - Set featured: true in the front matter to show an event or news item on the homepage - Set featured: false or omit the field to hide from homepage - All items appear on their respective listing pages (events.qmd or news.qmd) regardless of featured status\n\n\n\n\nThe site uses a two-stage deployment process:\n\nGitHub Actions (/.github/workflows/quarto-build.yml) builds the site on every commit to main:\n\nRuns quarto render automatically\nPublishes built site to deploy branch\nUses peaceiris/actions-gh-pages action\n\nNetlify serves the pre-built site from the deploy branch:\n\nNo build step on Netlify (configured in netlify.toml)\nSimply serves static files from the branch\nLive site: www.i3open.org\n\n\nSimply commit and push changes to main to trigger the build and deployment. No need to manually run quarto render."
  },
  {
    "objectID": "CLAUDE.html#project-overview",
    "href": "CLAUDE.html#project-overview",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This is the Innovation Information Initiative (I³) website, built with Quarto and migrated from PubPub. It’s a static website for a data collaborative focused on open innovation data, patent datasets, citation graphs, and related analytics tools."
  },
  {
    "objectID": "CLAUDE.html#development-commands",
    "href": "CLAUDE.html#development-commands",
    "title": "CLAUDE.md",
    "section": "",
    "text": "quarto preview\nThis starts a local development server with live reload. The site will be available at http://localhost:XXXX (port will be shown in output).\n\n\n\nquarto render\nThis generates static files in the _site/ directory, which is the output directory for deployment.\n\n\n\nquarto --version"
  },
  {
    "objectID": "CLAUDE.html#architecture-and-structure",
    "href": "CLAUDE.html#architecture-and-structure",
    "title": "CLAUDE.md",
    "section": "",
    "text": "The site uses automatic content discovery with folder-based organization:\n\nEvents and News use folder structures with individual index.qmd files\nQuarto listing feature automatically discovers and displays content\nFeatured filtering controls which items appear on the homepage using featured: true in YAML front matter\nPublications still use publications.yml for centralized management\n\nAll template content from Deep Policy Lab has been removed - the site is clean and ready for I³ content migration.\n\n\n\n\n_quarto.yml: Main site configuration including navbar, theme, search, and global settings\nindex.qmd: Homepage with custom layout using Quarto listing blocks for news/events/publications\nreferences.bib: Bibliography file for academic citations\n\n\n\n\nNews: Folder-based structure with automatic discovery - Location: news/item-name/index.qmd - Required front matter: title, subtitle, description, author, date, image, categories - Images stored in: news/item-name/images/ - Set featured: true to display on homepage - All news items automatically appear on news.qmd\nEvents: Folder-based structure with automatic discovery - Location: events/event-name/index.qmd - Required front matter: title, subtitle, description, author, date, image, categories - Images stored in: events/event-name/images/ - Set featured: true to display on homepage - All events automatically appear on events.qmd\nPublications: Add entries to publications.yml - Fields: path, image, title, subtitle, description, date, fulltext, categories - Displayed on publications.qmd and homepage - Can filter by categories (e.g., “featured”)\nEssays: Create individual .qmd files - Page: essays.qmd\nDatasets: Edit datasets.qmd directly with dataset information\n\n\n\nThe site uses Quarto’s listing feature with automatic discovery and filtering:\nHomepage (index.qmd): - #news-events listing: Auto-discovers from events/*/index.qmd and news/*/index.qmd - Uses include: featured: true to filter homepage items - Shows only content marked as featured: true in front matter - #publications listing: Pulls from publications.yml\nIndividual listing pages: - events.qmd: Auto-discovers all events from events/*/index.qmd - news.qmd: Auto-discovers all news from news/*/index.qmd\nListing features: - Automatic content discovery using glob patterns - Sorting (e.g., “date desc”) - Multiple content sources - Grid/table layouts - Filtering by YAML front matter fields using include/exclude - Custom field display\n\n\n\n\nstyles.css: Main site stylesheet\ncustom.css: Additional custom styles (used on homepage)\ncenter.css: Specific layout styles\nTheme set to “cosmo” in _quarto.yml\nNavbar colors: background #05336B, foreground #FFFFFF\n\n\n\n\n\nevents/*/images/: Event-specific images (stored with each event)\nnews/*/images/: News-specific images (stored with each news item)\n/files/images/: Legacy image storage for publications, people, shared assets\n/files/includes/: Reusable content snippets (analytics, social sharing)\n\n_msclarity.qmd: Microsoft Clarity analytics\n_mswebmaster.js: Webmaster verification\n_academic.qmd, _socialshare.qmd: Template includes\n\n\n\n\n\n\nStandard pages: Use page-layout: full (About, News, Events, Publications, etc.)\nHomepage: Uses page-layout: custom with Quarto’s grid system\n\nGrid classes: .g-col-12, .g-col-md-7, etc.\nBackground frames: .background-frame, .alt-background\nContent blocks: .content-block\n\n\n\n\n\nThe site has a clean navigation structure in _quarto.yml: - About - I3 Essays - News - Events - Publications - Public Datasets - Contact\nAll placeholder/template pages have been removed."
  },
  {
    "objectID": "CLAUDE.html#adding-content",
    "href": "CLAUDE.html#adding-content",
    "title": "CLAUDE.md",
    "section": "",
    "text": "Add a news item: 1. Create folder: news/news-item-name/ 2. Create news/news-item-name/index.qmd with front matter: yaml    ---    title: \"News Item Title\"    subtitle: \"Brief subtitle\"    description: \"Longer description for listings\"    author: \"Author Name\"    date: \"YYYY-MM-DD\"    image: images/image-name.png    categories: [category1, category2]    featured: true  # Set to true to show on homepage    --- 3. Add images to news/news-item-name/images/ 4. Write content below front matter 5. Preview with quarto preview\nAdd an event: 1. Create folder: events/event-name/ 2. Create events/event-name/index.qmd with front matter: yaml    ---    title: \"Event Title\"    subtitle: \"Event subtitle\"    description: \"Event description for listings\"    author:      - Author One      - Author Two    date: \"YYYY-MM-DD\"    image: images/image-name.png    categories: [workshop, category2]    featured: true  # Set to true to show on homepage    --- 3. Add images to events/event-name/images/ 4. Write event details below front matter 5. Preview changes\nAdd a publication: 1. Open publications.yml 2. Add entry with path, image, title, subtitle, description, date, fulltext, categories 3. Use categories for filtering (e.g., “featured”) 4. Preview changes\nControlling homepage display: - Set featured: true in the front matter to show an event or news item on the homepage - Set featured: false or omit the field to hide from homepage - All items appear on their respective listing pages (events.qmd or news.qmd) regardless of featured status"
  },
  {
    "objectID": "CLAUDE.html#deployment",
    "href": "CLAUDE.html#deployment",
    "title": "CLAUDE.md",
    "section": "",
    "text": "The site uses a two-stage deployment process:\n\nGitHub Actions (/.github/workflows/quarto-build.yml) builds the site on every commit to main:\n\nRuns quarto render automatically\nPublishes built site to deploy branch\nUses peaceiris/actions-gh-pages action\n\nNetlify serves the pre-built site from the deploy branch:\n\nNo build step on Netlify (configured in netlify.toml)\nSimply serves static files from the branch\nLive site: www.i3open.org\n\n\nSimply commit and push changes to main to trigger the build and deployment. No need to manually run quarto render."
  },
  {
    "objectID": "fellows/current/randol-yao/index.html",
    "href": "fellows/current/randol-yao/index.html",
    "title": "Randol Yao",
    "section": "",
    "text": "i3 Fellow, 2026 Cohort"
  },
  {
    "objectID": "fellows/current/taoyu-long/index.html",
    "href": "fellows/current/taoyu-long/index.html",
    "title": "Taoyu Long",
    "section": "",
    "text": "i3 Fellow, 2026 Cohort"
  },
  {
    "objectID": "fellows/current/yanou-zhou/index.html",
    "href": "fellows/current/yanou-zhou/index.html",
    "title": "Yanou Zhou",
    "section": "",
    "text": "i3 Fellow, 2026 Cohort"
  },
  {
    "objectID": "fellows/alumni/rebekah-dix/index.html",
    "href": "fellows/alumni/rebekah-dix/index.html",
    "title": "Rebekah Dix",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  },
  {
    "objectID": "fellows/alumni/alexander-kann/index.html",
    "href": "fellows/alumni/alexander-kann/index.html",
    "title": "Alexander Kann",
    "section": "",
    "text": "i3 Fellow, 2024 Cohort"
  },
  {
    "objectID": "fellows/alumni/bernardo-dionisi/index.html",
    "href": "fellows/alumni/bernardo-dionisi/index.html",
    "title": "Bernardo Dionisi",
    "section": "",
    "text": "i3 Fellow, 2024 Cohort"
  },
  {
    "objectID": "fellows/alumni/matthew-lee-chen/index.html",
    "href": "fellows/alumni/matthew-lee-chen/index.html",
    "title": "Matthew Lee Chen",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  },
  {
    "objectID": "fellows/alumni/guilherme-junqueira/index.html",
    "href": "fellows/alumni/guilherme-junqueira/index.html",
    "title": "Guilherme Junqueira",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  },
  {
    "objectID": "fellows/alumni/tianshu-lyu/index.html",
    "href": "fellows/alumni/tianshu-lyu/index.html",
    "title": "Tianshu Lyu",
    "section": "",
    "text": "i3 Fellow, 2025 Cohort"
  }
]